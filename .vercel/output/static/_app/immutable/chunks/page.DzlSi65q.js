import{s as qt,q as An,F as Gt,a as C,e as z,J as T,g as v,c as A,b as W,K as S,f as l,h as I,i as p,t as d,d as F,u as H,o as O,m as U}from"./scheduler.m8nR5Aoa.js";import{S as jt,i as Bt,b as f,d as h,m as $,a as g,t as y,e as u}from"./index.DmaBKroe.js";import{g as Rt,a as Tt}from"./index.CF6Y6_XD.js";import{L as Ht,H as ia,P as ha,B as St}from"./8.mPDhRuym.js";import{P as b,H as $a,U as zn,L as V}from"./ul.BG4kpopR.js";import{O as Ut}from"./ol.RSJyuz2J.js";import{I as ra}from"./img.D8KzVVhe.js";function Jt(r){let a;return{c(){a=d("On the second day of 100 days of AI, we're diving into one of the fundamental optimization algorithms used in machine learning: Gradient Descent. Gradient Descent is a first-order iterative optimization algorithm used to find the minimum of a function. In the context of machine learning, this function is often a cost function that represents the difference between the predicted and actual values in a model.")},l(n){a=F(n,"On the second day of 100 days of AI, we're diving into one of the fundamental optimization algorithms used in machine learning: Gradient Descent. Gradient Descent is a first-order iterative optimization algorithm used to find the minimum of a function. In the context of machine learning, this function is often a cost function that represents the difference between the predicted and actual values in a model.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Vt(r){let a;return{c(){a=d("What is Gradient Descent ?")},l(n){a=F(n,"What is Gradient Descent ?")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Yt(r){let a;return{c(){a=d(`Imagine you're blindfolded on a weird, lumpy landscape, trying to find the lowest point without falling over. You can only sense if you're going downhill or uphill. Gradient Descent is like this quirky adventure, but for finding the lowest point of a wacky mathematical "hill" that represents how wrong our guesses are. Instead of feeling the terrain, we use math to figure out which way is downhill, and then we take tiny, careful steps in that direction until we hit the bottom. It's like teaching a computer to dance its way to the best answers in a game or recognize cats in pictures — it's all about finding that sweet spot where things just work!`)},l(n){a=F(n,`Imagine you're blindfolded on a weird, lumpy landscape, trying to find the lowest point without falling over. You can only sense if you're going downhill or uphill. Gradient Descent is like this quirky adventure, but for finding the lowest point of a wacky mathematical "hill" that represents how wrong our guesses are. Instead of feeling the terrain, we use math to figure out which way is downhill, and then we take tiny, careful steps in that direction until we hit the bottom. It's like teaching a computer to dance its way to the best answers in a game or recognize cats in pictures — it's all about finding that sweet spot where things just work!`)},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Kt(r){let a;return{c(){a=d("Okay! That's not a technical definition of it. For people who love more technical definitions, Gradient Descent is an iterative optimization algorithm used to minimize a function by moving in the direction of the steepest descent, as defined by the negative of the gradient. The gradient represents the slope of the function at a given point, and moving in the opposite direction of the gradient allows us to descend toward the minimum of the function.")},l(n){a=F(n,"Okay! That's not a technical definition of it. For people who love more technical definitions, Gradient Descent is an iterative optimization algorithm used to minimize a function by moving in the direction of the steepest descent, as defined by the negative of the gradient. The gradient represents the slope of the function at a given point, and moving in the opposite direction of the gradient allows us to descend toward the minimum of the function.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Qt(r){let a;return{c(){a=d("In machine learning, this function is often a cost function that measures the difference between predicted and actual values. By iteratively adjusting the parameters of a model in the direction that decreases the cost function the most, Gradient Descent effectively optimizes the model's performance.")},l(n){a=F(n,"In machine learning, this function is often a cost function that measures the difference between predicted and actual values. By iteratively adjusting the parameters of a model in the direction that decreases the cost function the most, Gradient Descent effectively optimizes the model's performance.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Xt(r){let a,n,t="Batch Gradient Descent",i,o,m="Stochastic Gradient Descent",w,M,k="Mini-batch Gradient Descent",D;return{c(){a=d("There are different variants of Gradient Descent, such as "),n=z("strong"),n.textContent=t,i=d(", "),o=z("strong"),o.textContent=m,w=d(", and "),M=z("strong"),M.textContent=k,D=d(" (we will discuss about each of them in next series of posts), each with its own trade-offs in terms of computational efficiency and convergence speed. Overall, Gradient Descent is a fundamental tool for training machine learning models and is widely used in various optimization problems across different domains.")},l(E){a=F(E,"There are different variants of Gradient Descent, such as "),n=A(E,"STRONG",{"data-svelte-h":!0}),H(n)!=="svelte-1jusz12"&&(n.textContent=t),i=F(E,", "),o=A(E,"STRONG",{"data-svelte-h":!0}),H(o)!=="svelte-5vfpwd"&&(o.textContent=m),w=F(E,", and "),M=A(E,"STRONG",{"data-svelte-h":!0}),H(M)!=="svelte-12nqswi"&&(M.textContent=k),D=F(E," (we will discuss about each of them in next series of posts), each with its own trade-offs in terms of computational efficiency and convergence speed. Overall, Gradient Descent is a fundamental tool for training machine learning models and is widely used in various optimization problems across different domains.")},m(E,L){p(E,a,L),p(E,n,L),p(E,i,L),p(E,o,L),p(E,w,L),p(E,M,L),p(E,D,L)},p:O,d(E){E&&(l(a),l(n),l(i),l(o),l(w),l(M),l(D))}}}function Zt(r){let a;return{c(){a=d("Enough of definitions. It's time to work on it.")},l(n){a=F(n,"Enough of definitions. It's time to work on it.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function se(r){let a;return{c(){a=d("Requirements of Gradient Descent")},l(n){a=F(n,"Requirements of Gradient Descent")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ae(r){let a;return{c(){a=d("Gradient Descent doesn't work for all functions. It has it's own requirements that needs to be satisfied by the function. They are:")},l(n){a=F(n,"Gradient Descent doesn't work for all functions. It has it's own requirements that needs to be satisfied by the function. They are:")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ne(r){let a,n="Differentiability";return{c(){a=z("strong"),a.textContent=n},l(t){a=A(t,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-1oqeoo4"&&(a.textContent=n)},m(t,i){p(t,a,i)},p:O,d(t){t&&l(a)}}}function te(r){let a,n="Convexity (for global minimum)";return{c(){a=z("strong"),a.textContent=n},l(t){a=A(t,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-14mlr3q"&&(a.textContent=n)},m(t,i){p(t,a,i)},p:O,d(t){t&&l(a)}}}function ee(r){let a,n,t,i;return a=new V({props:{$$slots:{default:[ne]},$$scope:{ctx:r}}}),t=new V({props:{$$slots:{default:[te]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment),n=C(),f(t.$$.fragment)},l(o){h(a.$$.fragment,o),n=v(o),h(t.$$.fragment,o)},m(o,m){$(a,o,m),p(o,n,m),$(t,o,m),i=!0},p(o,m){const w={};m&2&&(w.$$scope={dirty:m,ctx:o}),a.$set(w);const M={};m&2&&(M.$$scope={dirty:m,ctx:o}),t.$set(M)},i(o){i||(g(a.$$.fragment,o),g(t.$$.fragment,o),i=!0)},o(o){y(a.$$.fragment,o),y(t.$$.fragment,o),i=!1},d(o){o&&l(n),u(a,o),u(t,o)}}}function le(r){let a;return{c(){a=d("Differentiability")},l(n){a=F(n,"Differentiability")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function pe(r){let a;return{c(){a=d("What does it mean ? Well, The function to be minimized must be differentiable, meaning its derivative exists at every point where it's being optimized — not all functions meet these criteria.")},l(n){a=F(n,"What does it mean ? Well, The function to be minimized must be differentiable, meaning its derivative exists at every point where it's being optimized — not all functions meet these criteria.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function oe(r){let a;return{c(){a=d("Let's see some example functions that meet this criteria.")},l(n){a=F(n,"Let's see some example functions that meet this criteria.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ie(r){let a;return{c(){a=d("Where as, non-differentiable functions have a step a cusp or a discontinuity:")},l(n){a=F(n,"Where as, non-differentiable functions have a step a cusp or a discontinuity:")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function re(r){let a;return{c(){a=d("by now, you might have an idea about Differentiability of a function. The next requirement is Convexity.")},l(n){a=F(n,"by now, you might have an idea about Differentiability of a function. The next requirement is Convexity.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function me(r){let a;return{c(){a=d("Convexity")},l(n){a=F(n,"Convexity")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ce(r){let a;return{c(){a=d("If the goal is to find the global minimum, the function should be convex, meaning it has a single minimum that Gradient Descent can converge to.")},l(n){a=F(n,"If the goal is to find the global minimum, the function should be convex, meaning it has a single minimum that Gradient Descent can converge to.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function fe(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>',o,m,w,M='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">x1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord mathnormal">x</span><span class="mord">1</span></span></span></span>',k,D,E,L='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">x2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord mathnormal">x</span><span class="mord">2</span></span></span></span>',_;return{c(){a=d("A function "),n=z("span"),t=new T(!1),o=d(" is said to be convex over an interval if, for any two points "),m=z("span"),w=new T(!1),k=d(" and "),D=z("span"),E=new T(!1),_=d(" in that interval, the line segment connecting the points lies above the graph of the function:"),this.h()},l(c){a=F(c,"A function "),n=A(c,"SPAN",{class:!0});var x=W(n);t=S(x,!1),x.forEach(l),o=F(c," is said to be convex over an interval if, for any two points "),m=A(c,"SPAN",{class:!0});var q=W(m);w=S(q,!1),q.forEach(l),k=F(c," and "),D=A(c,"SPAN",{class:!0});var N=W(D);E=S(N,!1),N.forEach(l),_=F(c," in that interval, the line segment connecting the points lies above the graph of the function:"),this.h()},h(){t.a=null,I(n,"class","text-base"),w.a=null,I(m,"class","text-base"),E.a=null,I(D,"class","text-base")},m(c,x){p(c,a,x),p(c,n,x),t.m(i,n),p(c,o,x),p(c,m,x),w.m(M,m),p(c,k,x),p(c,D,x),E.m(L,D),p(c,_,x)},p:O,d(c){c&&(l(a),l(n),l(o),l(m),l(k),l(D),l(_))}}}function he(r){let a,n;return a=new V({props:{$$slots:{default:[fe]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function $e(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><mi>λ</mi><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 leq lambda leq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>',o;return{c(){a=d("where "),n=z("span"),t=new T(!1),o=d(" This property is known as Jensen's inequality."),this.h()},l(m){a=F(m,"where "),n=A(m,"SPAN",{class:!0});var w=W(n);t=S(w,!1),w.forEach(l),o=F(m," This property is known as Jensen's inequality."),this.h()},h(){t.a=null,I(n,"class","text-base")},m(m,w){p(m,a,w),p(m,n,w),t.m(i,n),p(m,o,w)},p:O,d(m){m&&(l(a),l(n),l(o))}}}function ge(r){let a;return{c(){a=d("Geometrically, a function is convex if its graph does not curve downward. In other words, if you draw a line between any two points on the graph, the line lies above the graph itself.")},l(n){a=F(n,"Geometrically, a function is convex if its graph does not curve downward. In other words, if you draw a line between any two points on the graph, the line lies above the graph itself.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ye(r){let a;return{c(){a=d("Another way to check mathematically if a univariate function is convex is to calculate the second derivative and check if its value is always bigger than 0.")},l(n){a=F(n,"Another way to check mathematically if a univariate function is convex is to calculate the second derivative and check if its value is always bigger than 0.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ue(r){let a,n,t,i;return a=new V({props:{$$slots:{default:[ge]},$$scope:{ctx:r}}}),t=new V({props:{$$slots:{default:[ye]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment),n=C(),f(t.$$.fragment)},l(o){h(a.$$.fragment,o),n=v(o),h(t.$$.fragment,o)},m(o,m){$(a,o,m),p(o,n,m),$(t,o,m),i=!0},p(o,m){const w={};m&2&&(w.$$scope={dirty:m,ctx:o}),a.$set(w);const M={};m&2&&(M.$$scope={dirty:m,ctx:o}),t.$set(M)},i(o){i||(g(a.$$.fragment,o),g(t.$$.fragment,o),i=!0)},o(o){y(a.$$.fragment,o),y(t.$$.fragment,o),i=!1},d(o){o&&l(n),u(a,o),u(t,o)}}}function de(r){let a;return{c(){a=d("Let's move on.")},l(n){a=F(n,"Let's move on.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Fe(r){let a;return{c(){a=d("But what is a Gradient ?")},l(n){a=F(n,"But what is a Gradient ?")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function _e(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>',o,m,w,M='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi><mi>f</mi></mrow><annotation encoding="application/x-tex">&#92;nabla f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>',k,D,E,L='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mo separator="true">,</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow></mfrac><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">left( \frac&#123;partial f&#125;&#123;partial x&#125;, \frac&#123;partial f&#125;&#123;partial y&#125; &#92;right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">x</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4811em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span>',_;return{c(){a=d('In the context of Gradient Descent, the "gradient" is a vector that contains the partial derivatives of a function with respect to each of its variables. For example, if you have a function '),n=z("span"),t=new T(!1),o=d(", its gradient "),m=z("span"),w=new T(!1),k=d(" is a vector "),D=z("span"),E=new T(!1),_=d(". This vector points in the direction of the steepest increase of the function at a specific point."),this.h()},l(c){a=F(c,'In the context of Gradient Descent, the "gradient" is a vector that contains the partial derivatives of a function with respect to each of its variables. For example, if you have a function '),n=A(c,"SPAN",{class:!0});var x=W(n);t=S(x,!1),x.forEach(l),o=F(c,", its gradient "),m=A(c,"SPAN",{class:!0});var q=W(m);w=S(q,!1),q.forEach(l),k=F(c," is a vector "),D=A(c,"SPAN",{class:!0});var N=W(D);E=S(N,!1),N.forEach(l),_=F(c,". This vector points in the direction of the steepest increase of the function at a specific point."),this.h()},h(){t.a=null,I(n,"class","text-base"),w.a=null,I(m,"class","text-base"),E.a=null,I(D,"class","text-base")},m(c,x){p(c,a,x),p(c,n,x),t.m(i,n),p(c,o,x),p(c,m,x),w.m(M,m),p(c,k,x),p(c,D,x),E.m(L,D),p(c,_,x)},p:O,d(c){c&&(l(a),l(n),l(o),l(m),l(k),l(D),l(_))}}}function we(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span>',o,m,w,M='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>',k,D,E,L='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>',_,c,x,q='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>',N,B,j,K='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>',R;return{c(){a=d("When you're using Gradient Descent to minimize a function "),n=z("span"),t=new T(!1),o=d(", where "),m=z("span"),w=new T(!1),k=d(" is a vector of parameters (like weights in a machine learning model), you want to find the values of "),D=z("span"),E=new T(!1),_=d(" that minimize "),c=z("span"),x=new T(!1),N=d(". To do this, you start with an initial guess for "),B=z("span"),j=new T(!1),R=d(" and then update it iteratively using the gradient."),this.h()},l(G){a=F(G,"When you're using Gradient Descent to minimize a function "),n=A(G,"SPAN",{class:!0});var P=W(n);t=S(P,!1),P.forEach(l),o=F(G,", where "),m=A(G,"SPAN",{class:!0});var Ys=W(m);w=S(Ys,!1),Ys.forEach(l),k=F(G," is a vector of parameters (like weights in a machine learning model), you want to find the values of "),D=A(G,"SPAN",{class:!0});var J=W(D);E=S(J,!1),J.forEach(l),_=F(G," that minimize "),c=A(G,"SPAN",{class:!0});var Ks=W(c);x=S(Ks,!1),Ks.forEach(l),N=F(G,". To do this, you start with an initial guess for "),B=A(G,"SPAN",{class:!0});var Y=W(B);j=S(Y,!1),Y.forEach(l),R=F(G," and then update it iteratively using the gradient."),this.h()},h(){t.a=null,I(n,"class","text-base"),w.a=null,I(m,"class","text-base"),E.a=null,I(D,"class","text-base"),x.a=null,I(c,"class","text-base"),j.a=null,I(B,"class","text-base")},m(G,P){p(G,a,P),p(G,n,P),t.m(i,n),p(G,o,P),p(G,m,P),w.m(M,m),p(G,k,P),p(G,D,P),E.m(L,D),p(G,_,P),p(G,c,P),x.m(q,c),p(G,N,P),p(G,B,P),j.m(K,B),p(G,R,P)},p:O,d(G){G&&(l(a),l(n),l(o),l(m),l(k),l(D),l(_),l(c),l(N),l(B),l(R))}}}function Ce(r){let a;return{c(){a=d("The update rule is:")},l(n){a=F(n,"The update rule is:")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ve(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>',o,m,w,M='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mi mathvariant="normal">∇</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">alpha &#92;nabla f(W_&#123;old&#125;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>',k,D,E,L='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W^&#123;old&#125;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>',_;return{c(){a=d("Here, "),n=z("span"),t=new T(!1),o=d(` is the learning rate, which controls how big the steps are that we take in the direction of the negative gradient. By subtracting,
`),m=z("span"),w=new T(!1),k=d(" from "),D=z("span"),E=new T(!1),_=d(" we're effectively moving in the direction opposite to the gradient, which is the direction of the steepest decrease of the function."),this.h()},l(c){a=F(c,"Here, "),n=A(c,"SPAN",{class:!0});var x=W(n);t=S(x,!1),x.forEach(l),o=F(c,` is the learning rate, which controls how big the steps are that we take in the direction of the negative gradient. By subtracting,
`),m=A(c,"SPAN",{class:!0});var q=W(m);w=S(q,!1),q.forEach(l),k=F(c," from "),D=A(c,"SPAN",{class:!0});var N=W(D);E=S(N,!1),N.forEach(l),_=F(c," we're effectively moving in the direction opposite to the gradient, which is the direction of the steepest decrease of the function."),this.h()},h(){t.a=null,I(n,"class","text-base"),w.a=null,I(m,"class","text-base"),E.a=null,I(D,"class","text-base")},m(c,x){p(c,a,x),p(c,n,x),t.m(i,n),p(c,o,x),p(c,m,x),w.m(M,m),p(c,k,x),p(c,D,x),E.m(L,D),p(c,_,x)},p:O,d(c){c&&(l(a),l(n),l(o),l(m),l(k),l(D),l(_))}}}function Ee(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>',o;return{c(){a=d("By repeating this process, updating "),n=z("span"),t=new T(!1),o=d(" with each step, you gradually descend towards the minimum of the function. The gradient provides the direction for each step, helping you navigate towards the lowest point (minimum) of the function."),this.h()},l(m){a=F(m,"By repeating this process, updating "),n=A(m,"SPAN",{class:!0});var w=W(n);t=S(w,!1),w.forEach(l),o=F(m," with each step, you gradually descend towards the minimum of the function. The gradient provides the direction for each step, helping you navigate towards the lowest point (minimum) of the function."),this.h()},h(){t.a=null,I(n,"class","text-base")},m(m,w){p(m,a,w),p(m,n,w),t.m(i,n),p(m,o,w)},p:O,d(m){m&&(l(a),l(n),l(o))}}}function xe(r){let a;return{c(){a=d("Significance of Learning Rate")},l(n){a=F(n,"Significance of Learning Rate")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function De(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>',o;return{c(){a=d("The learning rate ("),n=z("span"),t=new T(!1),o=d(") is a crucial hyperparameter in the Gradient Descent algorithm that determines the size of the steps taken during each iteration towards minimizing the loss function. Here's the significance of the learning rate:"),this.h()},l(m){a=F(m,"The learning rate ("),n=A(m,"SPAN",{class:!0});var w=W(n);t=S(w,!1),w.forEach(l),o=F(m,") is a crucial hyperparameter in the Gradient Descent algorithm that determines the size of the steps taken during each iteration towards minimizing the loss function. Here's the significance of the learning rate:"),this.h()},h(){t.a=null,I(n,"class","text-base")},m(m,w){p(m,a,w),p(m,n,w),t.m(i,n),p(m,o,w)},p:O,d(m){m&&(l(a),l(n),l(o))}}}function be(r){let a,n="Controls Step Size",t;return{c(){a=z("strong"),a.textContent=n,t=d(": The learning rate dictates how much the parameters (weights) of the model should be adjusted with each iteration. A larger learning rate means taking larger steps, while a smaller learning rate means taking smaller steps.")},l(i){a=A(i,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-1vyoajl"&&(a.textContent=n),t=F(i,": The learning rate dictates how much the parameters (weights) of the model should be adjusted with each iteration. A larger learning rate means taking larger steps, while a smaller learning rate means taking smaller steps.")},m(i,o){p(i,a,o),p(i,t,o)},p:O,d(i){i&&(l(a),l(t))}}}function ke(r){let a,n;return a=new b({props:{$$slots:{default:[be]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function ze(r){let a,n="Impact on Convergence",t;return{c(){a=z("strong"),a.textContent=n,t=d(": The choice of learning rate can significantly impact the convergence of the algorithm. If the learning rate is too large, the algorithm may overshoot the minimum and fail to converge. On the other hand, if the learning rate is too small, the algorithm may take too long to converge or get stuck in a local minimum.")},l(i){a=A(i,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-15o3upk"&&(a.textContent=n),t=F(i,": The choice of learning rate can significantly impact the convergence of the algorithm. If the learning rate is too large, the algorithm may overshoot the minimum and fail to converge. On the other hand, if the learning rate is too small, the algorithm may take too long to converge or get stuck in a local minimum.")},m(i,o){p(i,a,o),p(i,t,o)},p:O,d(i){i&&(l(a),l(t))}}}function Ae(r){let a,n;return a=new b({props:{$$slots:{default:[ze]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function Me(r){let a,n="Trade-off between",t;return{c(){a=z("strong"),a.textContent=n,t=d(" Speed and Accuracy: A higher learning rate can lead to faster convergence, but it may also cause oscillations or overshooting around the minimum. Conversely, a lower learning rate may converge more slowly but with greater stability.")},l(i){a=A(i,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-oh6muc"&&(a.textContent=n),t=F(i," Speed and Accuracy: A higher learning rate can lead to faster convergence, but it may also cause oscillations or overshooting around the minimum. Conversely, a lower learning rate may converge more slowly but with greater stability.")},m(i,o){p(i,a,o),p(i,t,o)},p:O,d(i){i&&(l(a),l(t))}}}function Ge(r){let a,n;return a=new b({props:{$$slots:{default:[Me]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function Te(r){let a,n="Sensitive to Scale",t;return{c(){a=z("strong"),a.textContent=n,t=d(": The learning rate is sensitive to the scale of the input features and the magnitude of the gradients. Rescaling the features or using techniques like batch normalization can help in choosing an appropriate learning rate.")},l(i){a=A(i,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-1vn1dp7"&&(a.textContent=n),t=F(i,": The learning rate is sensitive to the scale of the input features and the magnitude of the gradients. Rescaling the features or using techniques like batch normalization can help in choosing an appropriate learning rate.")},m(i,o){p(i,a,o),p(i,t,o)},p:O,d(i){i&&(l(a),l(t))}}}function Se(r){let a,n;return a=new b({props:{$$slots:{default:[Te]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function We(r){let a,n="Hyperparameter Tuning:",t;return{c(){a=z("strong"),a.textContent=n,t=d(" Selecting an optimal learning rate often involves hyperparameter tuning. It is common to experiment with different learning rates to find the one that results in the fastest convergence without oscillations or divergence.")},l(i){a=A(i,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-4joqtk"&&(a.textContent=n),t=F(i," Selecting an optimal learning rate often involves hyperparameter tuning. It is common to experiment with different learning rates to find the one that results in the fastest convergence without oscillations or divergence.")},m(i,o){p(i,a,o),p(i,t,o)},p:O,d(i){i&&(l(a),l(t))}}}function Ie(r){let a,n;return a=new b({props:{$$slots:{default:[We]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function Le(r){let a,n="Adaptive Learning Rates",t;return{c(){a=z("strong"),a.textContent=n,t=d(": There are variations of Gradient Descent, such as AdaGrad, RMSprop, and Adam, which adapt the learning rate during training based on the history of gradients. These adaptive methods can often converge faster and more reliably than using a fixed learning rate.")},l(i){a=A(i,"STRONG",{"data-svelte-h":!0}),H(a)!=="svelte-n2gw1r"&&(a.textContent=n),t=F(i,": There are variations of Gradient Descent, such as AdaGrad, RMSprop, and Adam, which adapt the learning rate during training based on the history of gradients. These adaptive methods can often converge faster and more reliably than using a fixed learning rate.")},m(i,o){p(i,a,o),p(i,t,o)},p:O,d(i){i&&(l(a),l(t))}}}function Ne(r){let a,n;return a=new b({props:{$$slots:{default:[Le]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function Oe(r){let a,n,t,i,o,m,w,M,k,D,E,L;return a=new V({props:{$$slots:{default:[ke]},$$scope:{ctx:r}}}),t=new V({props:{$$slots:{default:[Ae]},$$scope:{ctx:r}}}),o=new V({props:{$$slots:{default:[Ge]},$$scope:{ctx:r}}}),w=new V({props:{$$slots:{default:[Se]},$$scope:{ctx:r}}}),k=new V({props:{$$slots:{default:[Ie]},$$scope:{ctx:r}}}),E=new V({props:{$$slots:{default:[Ne]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment),n=C(),f(t.$$.fragment),i=C(),f(o.$$.fragment),m=C(),f(w.$$.fragment),M=C(),f(k.$$.fragment),D=C(),f(E.$$.fragment)},l(_){h(a.$$.fragment,_),n=v(_),h(t.$$.fragment,_),i=v(_),h(o.$$.fragment,_),m=v(_),h(w.$$.fragment,_),M=v(_),h(k.$$.fragment,_),D=v(_),h(E.$$.fragment,_)},m(_,c){$(a,_,c),p(_,n,c),$(t,_,c),p(_,i,c),$(o,_,c),p(_,m,c),$(w,_,c),p(_,M,c),$(k,_,c),p(_,D,c),$(E,_,c),L=!0},p(_,c){const x={};c&2&&(x.$$scope={dirty:c,ctx:_}),a.$set(x);const q={};c&2&&(q.$$scope={dirty:c,ctx:_}),t.$set(q);const N={};c&2&&(N.$$scope={dirty:c,ctx:_}),o.$set(N);const B={};c&2&&(B.$$scope={dirty:c,ctx:_}),w.$set(B);const j={};c&2&&(j.$$scope={dirty:c,ctx:_}),k.$set(j);const K={};c&2&&(K.$$scope={dirty:c,ctx:_}),E.$set(K)},i(_){L||(g(a.$$.fragment,_),g(t.$$.fragment,_),g(o.$$.fragment,_),g(w.$$.fragment,_),g(k.$$.fragment,_),g(E.$$.fragment,_),L=!0)},o(_){y(a.$$.fragment,_),y(t.$$.fragment,_),y(o.$$.fragment,_),y(w.$$.fragment,_),y(k.$$.fragment,_),y(E.$$.fragment,_),L=!1},d(_){_&&(l(n),l(i),l(m),l(M),l(D)),u(a,_),u(t,_),u(o,_),u(w,_),u(k,_),u(E,_)}}}function Pe(r){let a;return{c(){a=d("at this point, you have a solid understanding of Gradient Descent. Let's get our hands dirty by implementing it from scratch in Python.")},l(n){a=F(n,"at this point, you have a solid understanding of Gradient Descent. Let's get our hands dirty by implementing it from scratch in Python.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function qe(r){let a;return{c(){a=d("Python Implementation")},l(n){a=F(n,"Python Implementation")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function je(r){let a,n,t,i='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>5</mn><mi>x</mi><mo>+</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">f(x) = x^2 + 5x + 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6</span></span></span></span>',o;return{c(){a=d("let's take a simple quadratic function, "),n=z("span"),t=new T(!1),o=d(" and optimise it."),this.h()},l(m){a=F(m,"let's take a simple quadratic function, "),n=A(m,"SPAN",{class:!0});var w=W(n);t=S(w,!1),w.forEach(l),o=F(m," and optimise it."),this.h()},h(){t.a=null,I(n,"class","text-base")},m(m,w){p(m,a,w),p(m,n,w),t.m(i,n),p(m,o,w)},p:O,d(m){m&&(l(a),l(n),l(o))}}}function Be(r){let a;return{c(){a=d("function to optimise:")},l(n){a=F(n,"function to optimise:")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Re(r){let a;return{c(){a=d("derivative of the function:")},l(n){a=F(n,"derivative of the function:")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function He(r){let a;return{c(){a=d("let's code it.")},l(n){a=F(n,"let's code it.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Ue(r){let a,n=`<code data-language="py" data-theme="dark" style="display: grid;"><span data-line=""><span style="color: #86E1FC">import</span><span style="color: #C8D3F5"> numpy </span><span style="color: #86E1FC">as</span><span style="color: #C8D3F5"> np</span></span>
<span data-line=""><span style="color: #86E1FC">import</span><span style="color: #C8D3F5"> matplotlib</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">pyplot </span><span style="color: #86E1FC">as</span><span style="color: #C8D3F5"> plt</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C099FF">def</span><span style="color: #C8D3F5"> </span><span style="color: #82AAFF">gradient_descent</span><span style="color: #B4C2F0">(</span><span style="color: #FCA7EA">function_to_optimize</span><span style="color: #86E1FC">,</span></span>
<span data-line=""><span style="color: #C8D3F5">                     </span><span style="color: #FCA7EA">derivative</span><span style="color: #86E1FC">,</span></span>
<span data-line=""><span style="color: #C8D3F5">                     </span><span style="color: #FCA7EA">lr</span><span style="color: #86E1FC">:</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">float</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">0.1</span><span style="color: #86E1FC">,</span></span>
<span data-line=""><span style="color: #C8D3F5">                     </span><span style="color: #FCA7EA">initial_x</span><span style="color: #86E1FC">:</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">float</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">-</span><span style="color: #FF966C">6.5</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5">  </span><span style="color: #858AA6"># random</span></span>
<span data-line=""><span style="color: #C8D3F5">                     </span><span style="color: #FCA7EA">iterations</span><span style="color: #86E1FC">:</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">int</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">50</span><span style="color: #B4C2F0">):</span></span>
<span data-line=""><span style="color: #C8D3F5">    x_values </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">[</span><span style="color: #C8D3F5">initial_x</span><span style="color: #86E1FC">]</span></span>
<span data-line=""><span style="color: #C8D3F5">    costs </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">[</span><span style="color: #C8D3F5">function_to_optimize</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">initial_x</span><span style="color: #86E1FC">)]</span></span>
<span data-line=""><span style="color: #C8D3F5">    </span></span>
<span data-line=""><span style="color: #C8D3F5">    </span><span style="color: #86E1FC">for</span><span style="color: #C8D3F5"> i </span><span style="color: #86E1FC">in</span><span style="color: #C8D3F5"> </span><span style="color: #65BCFF">range</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">iterations</span><span style="color: #86E1FC">):</span></span>
<span data-line=""><span style="color: #C8D3F5">        current_x </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> x_values</span><span style="color: #86E1FC">[-</span><span style="color: #FF966C">1</span><span style="color: #86E1FC">]</span></span>
<span data-line=""><span style="color: #C8D3F5">        gradient </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> derivative</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">current_x</span><span style="color: #86E1FC">)</span></span>
<span data-line="" data-highlighted-line=""><span style="color: #C8D3F5">        new_x </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> current_x </span><span style="color: #86E1FC">-</span><span style="color: #C8D3F5"> lr </span><span style="color: #86E1FC">*</span><span style="color: #C8D3F5"> gradient</span></span>
<span data-line=""><span style="color: #C8D3F5">        </span></span>
<span data-line=""><span style="color: #C8D3F5">        x_values</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">append</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">new_x</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">        costs</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">append</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">function_to_optimize</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">new_x</span><span style="color: #86E1FC">))</span></span>
<span data-line=""><span style="color: #C8D3F5">        </span></span>
<span data-line=""><span style="color: #C8D3F5">    </span><span style="color: #86E1FC">return</span><span style="color: #C8D3F5"> x_values</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> costs</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> lr</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> iterations</span></span></code>`,t;return{c(){a=new T(!1),t=U(),this.h()},l(i){a=S(i,!1),t=U(),this.h()},h(){a.a=t},m(i,o){a.m(n,i,o),p(i,t,o)},p:O,d(i){i&&(l(t),a.d())}}}function Je(r){let a,n=`<code data-language="py" data-theme="light" style="display: grid;"><span data-line=""><span style="color: #D32F2F">import</span><span style="color: #24292EFF"> numpy </span><span style="color: #D32F2F">as</span><span style="color: #24292EFF"> np</span></span>
<span data-line=""><span style="color: #D32F2F">import</span><span style="color: #24292EFF"> matplotlib</span><span style="color: #212121">.</span><span style="color: #24292EFF">pyplot </span><span style="color: #D32F2F">as</span><span style="color: #24292EFF"> plt</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #D32F2F">def</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">gradient_descent</span><span style="color: #24292EFF">(</span><span style="color: #FF9800">function_to_optimize</span><span style="color: #212121">,</span></span>
<span data-line=""><span style="color: #24292EFF">                     </span><span style="color: #FF9800">derivative</span><span style="color: #212121">,</span></span>
<span data-line=""><span style="color: #24292EFF">                     </span><span style="color: #FF9800">lr</span><span style="color: #212121">:</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">float</span><span style="color: #24292EFF"> </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">0.1</span><span style="color: #212121">,</span></span>
<span data-line=""><span style="color: #24292EFF">                     </span><span style="color: #FF9800">initial_x</span><span style="color: #212121">:</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">float</span><span style="color: #24292EFF"> </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> </span><span style="color: #D32F2F">-</span><span style="color: #1976D2">6.5</span><span style="color: #212121">,</span><span style="color: #24292EFF">  </span><span style="color: #C2C3C5"># random</span></span>
<span data-line=""><span style="color: #24292EFF">                     </span><span style="color: #FF9800">iterations</span><span style="color: #212121">:</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">int</span><span style="color: #24292EFF"> </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">50</span><span style="color: #24292EFF">):</span></span>
<span data-line=""><span style="color: #24292EFF">    x_values </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> [initial_x]</span></span>
<span data-line=""><span style="color: #24292EFF">    costs </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> [</span><span style="color: #6F42C1">function_to_optimize</span><span style="color: #212121">(initial_x)</span><span style="color: #24292EFF">]</span></span>
<span data-line=""><span style="color: #24292EFF">    </span></span>
<span data-line=""><span style="color: #24292EFF">    </span><span style="color: #D32F2F">for</span><span style="color: #24292EFF"> i </span><span style="color: #D32F2F">in</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">range</span><span style="color: #212121">(iterations):</span></span>
<span data-line=""><span style="color: #24292EFF">        current_x </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> x_values</span><span style="color: #212121">[</span><span style="color: #D32F2F">-</span><span style="color: #1976D2">1</span><span style="color: #212121">]</span></span>
<span data-line=""><span style="color: #24292EFF">        gradient </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">derivative</span><span style="color: #212121">(current_x)</span></span>
<span data-line="" data-highlighted-line=""><span style="color: #24292EFF">        new_x </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> current_x </span><span style="color: #D32F2F">-</span><span style="color: #24292EFF"> lr </span><span style="color: #D32F2F">*</span><span style="color: #24292EFF"> gradient</span></span>
<span data-line=""><span style="color: #24292EFF">        </span></span>
<span data-line=""><span style="color: #24292EFF">        x_values</span><span style="color: #212121">.</span><span style="color: #6F42C1">append</span><span style="color: #212121">(new_x)</span></span>
<span data-line=""><span style="color: #24292EFF">        costs</span><span style="color: #212121">.</span><span style="color: #6F42C1">append</span><span style="color: #212121">(</span><span style="color: #6F42C1">function_to_optimize</span><span style="color: #212121">(new_x))</span></span>
<span data-line=""><span style="color: #24292EFF">        </span></span>
<span data-line=""><span style="color: #24292EFF">    </span><span style="color: #D32F2F">return</span><span style="color: #24292EFF"> x_values</span><span style="color: #212121">,</span><span style="color: #24292EFF"> costs</span><span style="color: #212121">,</span><span style="color: #24292EFF"> lr</span><span style="color: #212121">,</span><span style="color: #24292EFF"> iterations</span></span></code>`,t;return{c(){a=new T(!1),t=U(),this.h()},l(i){a=S(i,!1),t=U(),this.h()},h(){a.a=t},m(i,o){a.m(n,i,o),p(i,t,o)},p:O,d(i){i&&(l(t),a.d())}}}function Ve(r){let a;return{c(){a=d("let's create anotehr function that helps us to animate the Gradient Descent Optimisation")},l(n){a=F(n,"let's create anotehr function that helps us to animate the Gradient Descent Optimisation")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Ye(r){let a,n=`<code data-language="py" data-theme="dark" style="display: grid;"><span data-line=""><span style="color: #86E1FC">import</span><span style="color: #C8D3F5"> matplotlib</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">animation </span><span style="color: #86E1FC">as</span><span style="color: #C8D3F5"> animation</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C099FF">def</span><span style="color: #C8D3F5"> </span><span style="color: #82AAFF">create_animation</span><span style="color: #B4C2F0">(</span><span style="color: #FCA7EA">x_values</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">costs</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">lr</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">iterations</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">function_to_optimize</span><span style="color: #B4C2F0">):</span></span>
<span data-line=""><span style="color: #C8D3F5">    fig</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> ax </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> plt</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">subplots</span><span style="color: #86E1FC">(</span><span style="color: #FCA7EA">figsize</span><span style="color: #86E1FC">=(</span><span style="color: #FF966C">10</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">6</span><span style="color: #86E1FC">))</span></span>
<span data-line=""><span style="color: #C8D3F5">    plt</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">grid</span><span style="color: #86E1FC">()</span></span>
<span data-line=""><span style="color: #C8D3F5">    ax</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">set_xlim</span><span style="color: #86E1FC">(-</span><span style="color: #FF966C">7</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">2</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    ax</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">set_ylim</span><span style="color: #86E1FC">(-</span><span style="color: #FF966C">1</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">20</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    ax</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">set_xlabel</span><span style="color: #86E1FC">(</span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">x</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    ax</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">set_ylabel</span><span style="color: #86E1FC">(</span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">y</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    ax</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">set_title</span><span style="color: #86E1FC">(</span><span style="color: #C099FF">f</span><span style="color: #C3E88D">'Gradient Descent Optimization, lr = </span><span style="color: #FF98A4">&#123;</span><span style="color: #C8D3F5">lr</span><span style="color: #FF98A4">&#125;</span><span style="color: #C3E88D">'</span><span style="color: #86E1FC">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C8D3F5">    </span><span style="color: #858AA6"># init empty plots for function and optimization process</span></span>
<span data-line=""><span style="color: #C8D3F5">    x </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> np</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">linspace</span><span style="color: #86E1FC">(-</span><span style="color: #FF966C">7</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">2</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">100</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    y </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> function_to_optimize</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">x</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    function_line</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> ax</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">plot</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">x</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> y</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">r-</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">label</span><span style="color: #86E1FC">=</span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">Function to Optimize</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    optimization_line</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> ax</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">plot</span><span style="color: #86E1FC">([],</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">[],</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">bo-</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">label</span><span style="color: #86E1FC">=</span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">Gradient Descent Optimization</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C8D3F5">    </span><span style="color: #858AA6"># Update function for animation</span></span>
<span data-line=""><span style="color: #C8D3F5">    </span><span style="color: #C099FF">def</span><span style="color: #C8D3F5"> </span><span style="color: #82AAFF">update</span><span style="color: #B4C2F0">(</span><span style="color: #FCA7EA">frame</span><span style="color: #B4C2F0">):</span></span>
<span data-line=""><span style="color: #C8D3F5">        optimization_line</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">set_data</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">x_values</span><span style="color: #86E1FC">[:</span><span style="color: #C8D3F5">frame</span><span style="color: #86E1FC">+</span><span style="color: #FF966C">1</span><span style="color: #86E1FC">],</span><span style="color: #C8D3F5"> costs</span><span style="color: #86E1FC">[:</span><span style="color: #C8D3F5">frame</span><span style="color: #86E1FC">+</span><span style="color: #FF966C">1</span><span style="color: #86E1FC">])</span></span>
<span data-line=""><span style="color: #C8D3F5">        </span><span style="color: #86E1FC">return</span><span style="color: #C8D3F5"> optimization_line</span><span style="color: #86E1FC">,</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C8D3F5">    ani </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> animation</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">FuncAnimation</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">fig</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> update</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">frames</span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5">iterations</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">blit</span><span style="color: #86E1FC">=</span><span style="color: #FF98A4">True</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    plt</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">legend</span><span style="color: #86E1FC">(</span><span style="color: #FCA7EA">handles</span><span style="color: #86E1FC">=[</span><span style="color: #C8D3F5">function_line</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> optimization_line</span><span style="color: #86E1FC">],</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">loc</span><span style="color: #86E1FC">=</span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">upper right</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    ani</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">save</span><span style="color: #86E1FC">(</span><span style="color: #C099FF">f</span><span style="color: #C3E88D">'gradient_descent_animation_</span><span style="color: #FF98A4">&#123;</span><span style="color: #C8D3F5">lr</span><span style="color: #FF98A4">&#125;</span><span style="color: #C3E88D">.gif'</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">writer</span><span style="color: #86E1FC">=</span><span style="color: #86E1FC">'</span><span style="color: #C3E88D">pillow</span><span style="color: #86E1FC">'</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> </span><span style="color: #FCA7EA">fps</span><span style="color: #86E1FC">=</span><span style="color: #FF966C">5</span><span style="color: #86E1FC">)</span></span>
<span data-line=""><span style="color: #C8D3F5">    plt</span><span style="color: #86E1FC">.</span><span style="color: #C8D3F5">show</span><span style="color: #86E1FC">()</span></span></code>`,t;return{c(){a=new T(!1),t=U(),this.h()},l(i){a=S(i,!1),t=U(),this.h()},h(){a.a=t},m(i,o){a.m(n,i,o),p(i,t,o)},p:O,d(i){i&&(l(t),a.d())}}}function Ke(r){let a,n=`<code data-language="py" data-theme="light" style="display: grid;"><span data-line=""><span style="color: #D32F2F">import</span><span style="color: #24292EFF"> matplotlib</span><span style="color: #212121">.</span><span style="color: #24292EFF">animation </span><span style="color: #D32F2F">as</span><span style="color: #24292EFF"> animation</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #D32F2F">def</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">create_animation</span><span style="color: #24292EFF">(</span><span style="color: #FF9800">x_values</span><span style="color: #212121">,</span><span style="color: #24292EFF"> </span><span style="color: #FF9800">costs</span><span style="color: #212121">,</span><span style="color: #24292EFF"> </span><span style="color: #FF9800">lr</span><span style="color: #212121">,</span><span style="color: #24292EFF"> </span><span style="color: #FF9800">iterations</span><span style="color: #212121">,</span><span style="color: #24292EFF"> </span><span style="color: #FF9800">function_to_optimize</span><span style="color: #24292EFF">):</span></span>
<span data-line=""><span style="color: #24292EFF">    fig</span><span style="color: #212121">,</span><span style="color: #24292EFF"> ax </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> plt</span><span style="color: #212121">.</span><span style="color: #6F42C1">subplots</span><span style="color: #212121">(figsize</span><span style="color: #D32F2F">=</span><span style="color: #212121">(</span><span style="color: #1976D2">10</span><span style="color: #212121">, </span><span style="color: #1976D2">6</span><span style="color: #212121">))</span></span>
<span data-line=""><span style="color: #24292EFF">    plt</span><span style="color: #212121">.</span><span style="color: #6F42C1">grid</span><span style="color: #212121">()</span></span>
<span data-line=""><span style="color: #24292EFF">    ax</span><span style="color: #212121">.</span><span style="color: #6F42C1">set_xlim</span><span style="color: #212121">(</span><span style="color: #D32F2F">-</span><span style="color: #1976D2">7</span><span style="color: #212121">, </span><span style="color: #1976D2">2</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    ax</span><span style="color: #212121">.</span><span style="color: #6F42C1">set_ylim</span><span style="color: #212121">(</span><span style="color: #D32F2F">-</span><span style="color: #1976D2">1</span><span style="color: #212121">, </span><span style="color: #1976D2">20</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    ax</span><span style="color: #212121">.</span><span style="color: #6F42C1">set_xlabel</span><span style="color: #212121">(</span><span style="color: #22863A">'x'</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    ax</span><span style="color: #212121">.</span><span style="color: #6F42C1">set_ylabel</span><span style="color: #212121">(</span><span style="color: #22863A">'y'</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    ax</span><span style="color: #212121">.</span><span style="color: #6F42C1">set_title</span><span style="color: #212121">(</span><span style="color: #D32F2F">f</span><span style="color: #22863A">'Gradient Descent Optimization, lr = </span><span style="color: #1976D2">&#123;</span><span style="color: #212121">lr</span><span style="color: #1976D2">&#125;</span><span style="color: #22863A">'</span><span style="color: #212121">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #24292EFF">    </span><span style="color: #C2C3C5"># init empty plots for function and optimization process</span></span>
<span data-line=""><span style="color: #24292EFF">    x </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> np</span><span style="color: #212121">.</span><span style="color: #6F42C1">linspace</span><span style="color: #212121">(</span><span style="color: #D32F2F">-</span><span style="color: #1976D2">7</span><span style="color: #212121">, </span><span style="color: #1976D2">2</span><span style="color: #212121">, </span><span style="color: #1976D2">100</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    y </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">function_to_optimize</span><span style="color: #212121">(x)</span></span>
<span data-line=""><span style="color: #24292EFF">    function_line</span><span style="color: #212121">,</span><span style="color: #24292EFF"> </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> ax</span><span style="color: #212121">.</span><span style="color: #6F42C1">plot</span><span style="color: #212121">(x, y, </span><span style="color: #22863A">'r-'</span><span style="color: #212121">, label</span><span style="color: #D32F2F">=</span><span style="color: #22863A">'Function to Optimize'</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    optimization_line</span><span style="color: #212121">,</span><span style="color: #24292EFF"> </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> ax</span><span style="color: #212121">.</span><span style="color: #6F42C1">plot</span><span style="color: #212121">([], [], </span><span style="color: #22863A">'bo-'</span><span style="color: #212121">, label</span><span style="color: #D32F2F">=</span><span style="color: #22863A">'Gradient Descent Optimization'</span><span style="color: #212121">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #24292EFF">    </span><span style="color: #C2C3C5"># Update function for animation</span></span>
<span data-line=""><span style="color: #24292EFF">    </span><span style="color: #D32F2F">def</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">update</span><span style="color: #24292EFF">(</span><span style="color: #FF9800">frame</span><span style="color: #24292EFF">):</span></span>
<span data-line=""><span style="color: #24292EFF">        optimization_line</span><span style="color: #212121">.</span><span style="color: #6F42C1">set_data</span><span style="color: #212121">(x_values[:frame</span><span style="color: #D32F2F">+</span><span style="color: #1976D2">1</span><span style="color: #212121">], costs[:frame</span><span style="color: #D32F2F">+</span><span style="color: #1976D2">1</span><span style="color: #212121">])</span></span>
<span data-line=""><span style="color: #24292EFF">        </span><span style="color: #D32F2F">return</span><span style="color: #24292EFF"> optimization_line</span><span style="color: #212121">,</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #24292EFF">    ani </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> animation</span><span style="color: #212121">.</span><span style="color: #6F42C1">FuncAnimation</span><span style="color: #212121">(fig, update, frames</span><span style="color: #D32F2F">=</span><span style="color: #212121">iterations, blit</span><span style="color: #D32F2F">=</span><span style="color: #1976D2">True</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    plt</span><span style="color: #212121">.</span><span style="color: #6F42C1">legend</span><span style="color: #212121">(handles</span><span style="color: #D32F2F">=</span><span style="color: #212121">[function_line, optimization_line], loc</span><span style="color: #D32F2F">=</span><span style="color: #22863A">'upper right'</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    ani</span><span style="color: #212121">.</span><span style="color: #6F42C1">save</span><span style="color: #212121">(</span><span style="color: #D32F2F">f</span><span style="color: #22863A">'gradient_descent_animation_</span><span style="color: #1976D2">&#123;</span><span style="color: #212121">lr</span><span style="color: #1976D2">&#125;</span><span style="color: #22863A">.gif'</span><span style="color: #212121">, writer</span><span style="color: #D32F2F">=</span><span style="color: #22863A">'pillow'</span><span style="color: #212121">, fps</span><span style="color: #D32F2F">=</span><span style="color: #1976D2">5</span><span style="color: #212121">)</span></span>
<span data-line=""><span style="color: #24292EFF">    plt</span><span style="color: #212121">.</span><span style="color: #6F42C1">show</span><span style="color: #212121">()</span></span></code>`,t;return{c(){a=new T(!1),t=U(),this.h()},l(i){a=S(i,!1),t=U(),this.h()},h(){a.a=t},m(i,o){a.m(n,i,o),p(i,t,o)},p:O,d(i){i&&(l(t),a.d())}}}function Qe(r){let a;return{c(){a=d("let's play with these functions")},l(n){a=F(n,"let's play with these functions")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Xe(r){let a;return{c(){a=d("Plots at different learning rates")},l(n){a=F(n,"Plots at different learning rates")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Ze(r){let a,n=`<code data-language="py" data-theme="dark" style="display: grid;"><span data-line=""><span style="color: #C099FF">def</span><span style="color: #C8D3F5"> </span><span style="color: #82AAFF">function_to_optimize</span><span style="color: #B4C2F0">(</span><span style="color: #FCA7EA">x</span><span style="color: #B4C2F0">):</span></span>
<span data-line="" data-highlighted-line=""><span style="color: #C8D3F5">    </span><span style="color: #86E1FC">return</span><span style="color: #C8D3F5"> x</span><span style="color: #86E1FC">**</span><span style="color: #FF966C">2</span><span style="color: #C8D3F5"> </span><span style="color: #86E1FC">+</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">5</span><span style="color: #86E1FC">*</span><span style="color: #C8D3F5">x </span><span style="color: #86E1FC">+</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">6</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C099FF">def</span><span style="color: #C8D3F5"> </span><span style="color: #82AAFF">derivative</span><span style="color: #B4C2F0">(</span><span style="color: #FCA7EA">x</span><span style="color: #B4C2F0">):</span></span>
<span data-line="" data-highlighted-line=""><span style="color: #C8D3F5">    </span><span style="color: #86E1FC">return</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">2</span><span style="color: #86E1FC">*</span><span style="color: #C8D3F5">x </span><span style="color: #86E1FC">+</span><span style="color: #C8D3F5"> </span><span style="color: #FF966C">5</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C8D3F5">x_values</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> costs</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> lr</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> iterations </span><span style="color: #86E1FC">=</span><span style="color: #C8D3F5"> gradient_descent</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">function_to_optimize</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> derivative</span><span style="color: #86E1FC">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #C8D3F5">create_animation</span><span style="color: #86E1FC">(</span><span style="color: #C8D3F5">x_values</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> costs</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> lr</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> iterations</span><span style="color: #86E1FC">,</span><span style="color: #C8D3F5"> function_to_optimize</span><span style="color: #86E1FC">)</span></span></code>`,t;return{c(){a=new T(!1),t=U(),this.h()},l(i){a=S(i,!1),t=U(),this.h()},h(){a.a=t},m(i,o){a.m(n,i,o),p(i,t,o)},p:O,d(i){i&&(l(t),a.d())}}}function sl(r){let a,n=`<code data-language="py" data-theme="light" style="display: grid;"><span data-line=""><span style="color: #D32F2F">def</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">function_to_optimize</span><span style="color: #24292EFF">(</span><span style="color: #FF9800">x</span><span style="color: #24292EFF">):</span></span>
<span data-line="" data-highlighted-line=""><span style="color: #24292EFF">    </span><span style="color: #D32F2F">return</span><span style="color: #24292EFF"> x</span><span style="color: #D32F2F">**</span><span style="color: #1976D2">2</span><span style="color: #24292EFF"> </span><span style="color: #D32F2F">+</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">5</span><span style="color: #D32F2F">*</span><span style="color: #24292EFF">x </span><span style="color: #D32F2F">+</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">6</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #D32F2F">def</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">derivative</span><span style="color: #24292EFF">(</span><span style="color: #FF9800">x</span><span style="color: #24292EFF">):</span></span>
<span data-line="" data-highlighted-line=""><span style="color: #24292EFF">    </span><span style="color: #D32F2F">return</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">2</span><span style="color: #D32F2F">*</span><span style="color: #24292EFF">x </span><span style="color: #D32F2F">+</span><span style="color: #24292EFF"> </span><span style="color: #1976D2">5</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #24292EFF">x_values</span><span style="color: #212121">,</span><span style="color: #24292EFF"> costs</span><span style="color: #212121">,</span><span style="color: #24292EFF"> lr</span><span style="color: #212121">,</span><span style="color: #24292EFF"> iterations </span><span style="color: #D32F2F">=</span><span style="color: #24292EFF"> </span><span style="color: #6F42C1">gradient_descent</span><span style="color: #212121">(function_to_optimize, derivative)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color: #6F42C1">create_animation</span><span style="color: #212121">(x_values, costs, lr, iterations, function_to_optimize)</span></span></code>`,t;return{c(){a=new T(!1),t=U(),this.h()},l(i){a=S(i,!1),t=U(),this.h()},h(){a.a=t},m(i,o){a.m(n,i,o),p(i,t,o)},p:O,d(i){i&&(l(t),a.d())}}}function al(r){let a;return{c(){a=d("learning rate = 0.1")},l(n){a=F(n,"learning rate = 0.1")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function nl(r){let a,n,t="gradient_descent",i;return{c(){a=d("just play with the learning rate parameter in the "),n=z("code"),n.textContent=t,i=d(` function and see how learning rate affects the optimisation.
also you can play with different functions and iterations and see how it goes.`)},l(o){a=F(o,"just play with the learning rate parameter in the "),n=A(o,"CODE",{"data-svelte-h":!0}),H(n)!=="svelte-1jmmnm9"&&(n.textContent=t),i=F(o,` function and see how learning rate affects the optimisation.
also you can play with different functions and iterations and see how it goes.`)},m(o,m){p(o,a,m),p(o,n,m),p(o,i,m)},p:O,d(o){o&&(l(a),l(n),l(i))}}}function tl(r){let a;return{c(){a=d("as you can see, when learning rate set to 0.1, the optimisation tries to reach the minimum point and takes more steps to reach there. let's try with slightly higher learning rate 0.3.")},l(n){a=F(n,"as you can see, when learning rate set to 0.1, the optimisation tries to reach the minimum point and takes more steps to reach there. let's try with slightly higher learning rate 0.3.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function el(r){let a;return{c(){a=d("learning rate = 0.3")},l(n){a=F(n,"learning rate = 0.3")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ll(r){let a;return{c(){a=d("it starts from the initial point and takes a huge jump downward to reach the minimum. you can say this obvisouly took less steps.")},l(n){a=F(n,"it starts from the initial point and takes a huge jump downward to reach the minimum. you can say this obvisouly took less steps.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function pl(r){let a,n;return a=new b({props:{$$slots:{default:[ll]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function ol(r){let a;return{c(){a=d("let's have a look at an interesting case, learning rate = 0.9")},l(n){a=F(n,"let's have a look at an interesting case, learning rate = 0.9")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function il(r){let a;return{c(){a=d("learning rate = 0.9")},l(n){a=F(n,"learning rate = 0.9")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function rl(r){let a;return{c(){a=d("What just happend there?")},l(n){a=F(n,"What just happend there?")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ml(r){let a;return{c(){a=d("Well, it means that we're taking relatively large steps towards the minimum of our loss function. The negative and positive steps we're observing indicate that the algorithm is overshooting the minimum and then oscillating around it.")},l(n){a=F(n,"Well, it means that we're taking relatively large steps towards the minimum of our loss function. The negative and positive steps we're observing indicate that the algorithm is overshooting the minimum and then oscillating around it.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function cl(r){let a;return{c(){a=d("what happends if we go beyond 0.9 ? let's set learning rate = 1.0")},l(n){a=F(n,"what happends if we go beyond 0.9 ? let's set learning rate = 1.0")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function fl(r){let a;return{c(){a=d("learning rate = 1.0")},l(n){a=F(n,"learning rate = 1.0")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function hl(r){let a;return{c(){a=d("This doesn't even reach the minumum point. it just oscialtes between negative and positive.")},l(n){a=F(n,"This doesn't even reach the minumum point. it just oscialtes between negative and positive.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function $l(r){let a;return{c(){a=d("let's set our learning rate very low, something like 0.01, what do you think happens to our algorithm ? Let's have a look.")},l(n){a=F(n,"let's set our learning rate very low, something like 0.01, what do you think happens to our algorithm ? Let's have a look.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function gl(r){let a;return{c(){a=d("learning rate = 0.01")},l(n){a=F(n,"learning rate = 0.01")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function yl(r){let a;return{c(){a=d("well this too, did not reach its destination. it stopped midway. But hey, you might think that it's going downhill but why did it stop? well, it ran out of fuel. just kidding, it stopped because iterations are not enough to reach the minimum. if we do this for more iterations, it will reach eventually.")},l(n){a=F(n,"well this too, did not reach its destination. it stopped midway. But hey, you might think that it's going downhill but why did it stop? well, it ran out of fuel. just kidding, it stopped because iterations are not enough to reach the minimum. if we do this for more iterations, it will reach eventually.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function ul(r){let a;return{c(){a=d("So, to conclude, it's always recommended to keep the learing rate at optimum value. Not too low, or not too high. it's not something that is fixed for different set of problems. you just have to play with that and see what works best. That's why we have several other Optimising methods in Gradient Descent that optimises the learning rate. We will learn about them in next upcomming series. Stay tuned and that's all for now. G'Day.")},l(n){a=F(n,"So, to conclude, it's always recommended to keep the learing rate at optimum value. Not too low, or not too high. it's not something that is fixed for different set of problems. you just have to play with that and see what works best. That's why we have several other Optimising methods in Gradient Descent that optimises the learning rate. We will learn about them in next upcomming series. Stay tuned and that's all for now. G'Day.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function dl(r){let a;return{c(){a=d("In upcomming posts, we will see more hands on Gradio demos to let you guys play with the models right here.")},l(n){a=F(n,"In upcomming posts, we will see more hands on Gradio demos to let you guys play with the models right here.")},m(n,t){p(n,a,t)},d(n){n&&l(a)}}}function Fl(r){let a,n;return a=new b({props:{$$slots:{default:[dl]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment)},l(t){h(a.$$.fragment,t)},m(t,i){$(a,t,i),n=!0},p(t,i){const o={};i&2&&(o.$$scope={dirty:i,ctx:t}),a.$set(o)},i(t){n||(g(a.$$.fragment,t),n=!0)},o(t){y(a.$$.fragment,t),n=!1},d(t){u(a,t)}}}function _l(r){let a,n,t,i,o,m,w,M,k,D,E,L,_,c,x,q,N,B,j,K,R,G,P,Ys,J,Ks,Y,Fa,Q,_a,Qs,wa,X,Ca,Z,va,ss,Ea,as,xa,Xs,Da,It='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>λ</mi><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>≤</mo><mi>λ</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(lambda x_1 + (1-lambda)x_2) leq lambda f(x_1) + (1-lambda)f(x_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">λ</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>',ba,ns,ka,ts,za,Zs,Aa,Lt='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><msup><mi>d</mi><mn>2</mn></msup><mrow><mi>d</mi><msup><mi>x</mi><mn>2</mn></msup></mrow></mfrac><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\frac{d^2}{dx^2}f(x) geq 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1771em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4911em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span>',Ma,es,Ga,ls,Ta,ps,Sa,os,Wa,is,Ia,sa,La,Nt=`<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub><mo>−</mo><mi>α</mi><mi mathvariant="normal">∇</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W_{new} = W_{old} - alpha 
abla f(W_{old})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>`,Na,rs,Oa,ms,Pa,cs,qa,fs,ja,hs,Ba,$s,Ra,gs,Ha,ys,Ua,us,Ja,aa,Va,Ot='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>5</mn><mi>x</mi><mo>+</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">f(x) = x^2 + 5x + 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6</span></span></span></span></span>',Ya,ds,Ka,na,Qa,Pt='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mi>d</mi><mrow><mi>d</mi><mi>x</mi></mrow></mfrac><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>f</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><mi>x</mi><mo>+</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">\frac{d}{dx} f(x) = f&#x27;(x) = 2x + 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></span>',Xa,Fs,Za,_s,ws,Cs,sn,vs,an,Es,xs,Ds,nn,bs,tn,ks,en,zs,As,Ms,ln,Gs,pn,ta,on,Ts,rn,Ss,mn,Ws,cn,ea,fn,Is,hn,Ls,$n,Ns,gn,la,yn,Os,un,Ps,dn,qs,Fn,js,_n,pa,wn,Bs,Cn,Rs,vn,Hs,En,oa,xn,Us,Dn,Js,bn,Vs,kn;return a=new b({props:{$$slots:{default:[Jt]},$$scope:{ctx:r}}}),t=new $a({props:{id:"what-is-gradient-descent-?",headerTag:"h2",$$slots:{default:[Vt]},$$scope:{ctx:r}}}),o=new b({props:{$$slots:{default:[Yt]},$$scope:{ctx:r}}}),w=new b({props:{$$slots:{default:[Kt]},$$scope:{ctx:r}}}),k=new b({props:{$$slots:{default:[Qt]},$$scope:{ctx:r}}}),E=new b({props:{$$slots:{default:[Xt]},$$scope:{ctx:r}}}),_=new b({props:{$$slots:{default:[Zt]},$$scope:{ctx:r}}}),x=new $a({props:{id:"requirements-of-gradient-descent",headerTag:"h2",$$slots:{default:[se]},$$scope:{ctx:r}}}),N=new b({props:{$$slots:{default:[ae]},$$scope:{ctx:r}}}),j=new Ut({props:{$$slots:{default:[ee]},$$scope:{ctx:r}}}),R=new ia({props:{id:"differentiability",headerTag:"h3",$$slots:{default:[le]},$$scope:{ctx:r}}}),P=new b({props:{$$slots:{default:[pe]},$$scope:{ctx:r}}}),J=new b({props:{$$slots:{default:[oe]},$$scope:{ctx:r}}}),Y=new ra({props:{src:"/posts/gradient-descent/differentiable_funs_plots.png",alt:"Differentiable Functions"}}),Q=new b({props:{$$slots:{default:[ie]},$$scope:{ctx:r}}}),Qs=new ra({props:{src:"/posts/gradient-descent/non-diff-funcs.png",alt:"Non Differentiable Functions"}}),X=new b({props:{$$slots:{default:[re]},$$scope:{ctx:r}}}),Z=new ia({props:{id:"convexity",headerTag:"h3",$$slots:{default:[me]},$$scope:{ctx:r}}}),ss=new b({props:{$$slots:{default:[ce]},$$scope:{ctx:r}}}),as=new zn({props:{$$slots:{default:[he]},$$scope:{ctx:r}}}),ns=new b({props:{$$slots:{default:[$e]},$$scope:{ctx:r}}}),ts=new zn({props:{$$slots:{default:[ue]},$$scope:{ctx:r}}}),es=new b({props:{$$slots:{default:[de]},$$scope:{ctx:r}}}),ls=new $a({props:{id:"but-what-is-a-gradient-?",headerTag:"h2",$$slots:{default:[Fe]},$$scope:{ctx:r}}}),ps=new b({props:{$$slots:{default:[_e]},$$scope:{ctx:r}}}),os=new b({props:{$$slots:{default:[we]},$$scope:{ctx:r}}}),is=new b({props:{$$slots:{default:[Ce]},$$scope:{ctx:r}}}),rs=new b({props:{$$slots:{default:[ve]},$$scope:{ctx:r}}}),ms=new b({props:{$$slots:{default:[Ee]},$$scope:{ctx:r}}}),cs=new $a({props:{id:"significance-of-learning-rate",headerTag:"h2",$$slots:{default:[xe]},$$scope:{ctx:r}}}),fs=new b({props:{$$slots:{default:[De]},$$scope:{ctx:r}}}),hs=new zn({props:{$$slots:{default:[Oe]},$$scope:{ctx:r}}}),$s=new b({props:{$$slots:{default:[Pe]},$$scope:{ctx:r}}}),gs=new $a({props:{id:"python-implementation",headerTag:"h2",$$slots:{default:[qe]},$$scope:{ctx:r}}}),ys=new b({props:{$$slots:{default:[je]},$$scope:{ctx:r}}}),us=new b({props:{$$slots:{default:[Be]},$$scope:{ctx:r}}}),ds=new b({props:{$$slots:{default:[Re]},$$scope:{ctx:r}}}),Fs=new b({props:{$$slots:{default:[He]},$$scope:{ctx:r}}}),ws=new ha({props:{class:"Moonlight II",tabindex:"0","data-language":"py","data-theme":"dark",$$slots:{default:[Ue]},$$scope:{ctx:r}}}),Cs=new ha({props:{class:"min-light",tabindex:"0","data-language":"py","data-theme":"light",$$slots:{default:[Je]},$$scope:{ctx:r}}}),vs=new b({props:{$$slots:{default:[Ve]},$$scope:{ctx:r}}}),xs=new ha({props:{class:"Moonlight II",tabindex:"0","data-language":"py","data-theme":"dark",$$slots:{default:[Ye]},$$scope:{ctx:r}}}),Ds=new ha({props:{class:"min-light",tabindex:"0","data-language":"py","data-theme":"light",$$slots:{default:[Ke]},$$scope:{ctx:r}}}),bs=new b({props:{$$slots:{default:[Qe]},$$scope:{ctx:r}}}),ks=new $a({props:{id:"plots-at-different-learning-rates",headerTag:"h2",$$slots:{default:[Xe]},$$scope:{ctx:r}}}),As=new ha({props:{class:"Moonlight II",tabindex:"0","data-language":"py","data-theme":"dark",$$slots:{default:[Ze]},$$scope:{ctx:r}}}),Ms=new ha({props:{class:"min-light",tabindex:"0","data-language":"py","data-theme":"light",$$slots:{default:[sl]},$$scope:{ctx:r}}}),Gs=new ia({props:{id:"learning-rate-=-0.1",headerTag:"h3",$$slots:{default:[al]},$$scope:{ctx:r}}}),ta=new ra({props:{src:"/posts/gradient-descent/gradient_descent_animation_0.1.gif",alt:"Gradient Descent @ lr = 0.1"}}),Ts=new b({props:{$$slots:{default:[nl]},$$scope:{ctx:r}}}),Ss=new b({props:{$$slots:{default:[tl]},$$scope:{ctx:r}}}),Ws=new ia({props:{id:"learning-rate-=-0.3",headerTag:"h3",$$slots:{default:[el]},$$scope:{ctx:r}}}),ea=new ra({props:{src:"/posts/gradient-descent/gradient_descent_animation_0.3.gif",alt:"Gradient Descent @ lr = 0.3"}}),Is=new St({props:{$$slots:{default:[pl]},$$scope:{ctx:r}}}),Ls=new b({props:{$$slots:{default:[ol]},$$scope:{ctx:r}}}),Ns=new ia({props:{id:"learning-rate-=-0.9",headerTag:"h3",$$slots:{default:[il]},$$scope:{ctx:r}}}),la=new ra({props:{src:"/posts/gradient-descent/gradient_descent_animation_0.9.gif",alt:"Gradient Descent @ lr = 0.9"}}),Os=new b({props:{$$slots:{default:[rl]},$$scope:{ctx:r}}}),Ps=new b({props:{$$slots:{default:[ml]},$$scope:{ctx:r}}}),qs=new b({props:{$$slots:{default:[cl]},$$scope:{ctx:r}}}),js=new ia({props:{id:"learning-rate-=-1.0",headerTag:"h3",$$slots:{default:[fl]},$$scope:{ctx:r}}}),pa=new ra({props:{src:"/posts/gradient-descent/gradient_descent_animation_1.gif",alt:"Gradient Descent @ lr = 1.0"}}),Bs=new b({props:{$$slots:{default:[hl]},$$scope:{ctx:r}}}),Rs=new b({props:{$$slots:{default:[$l]},$$scope:{ctx:r}}}),Hs=new ia({props:{id:"learning-rate-=-0.01",headerTag:"h3",$$slots:{default:[gl]},$$scope:{ctx:r}}}),oa=new ra({props:{src:"/posts/gradient-descent/gradient_descent_animation_0.01.gif",alt:"Gradient Descent @ lr = 0.01"}}),Us=new b({props:{$$slots:{default:[yl]},$$scope:{ctx:r}}}),Js=new b({props:{$$slots:{default:[ul]},$$scope:{ctx:r}}}),Vs=new St({props:{$$slots:{default:[Fl]},$$scope:{ctx:r}}}),{c(){f(a.$$.fragment),n=C(),f(t.$$.fragment),i=C(),f(o.$$.fragment),m=C(),f(w.$$.fragment),M=C(),f(k.$$.fragment),D=C(),f(E.$$.fragment),L=C(),f(_.$$.fragment),c=C(),f(x.$$.fragment),q=C(),f(N.$$.fragment),B=C(),f(j.$$.fragment),K=C(),f(R.$$.fragment),G=C(),f(P.$$.fragment),Ys=C(),f(J.$$.fragment),Ks=C(),f(Y.$$.fragment),Fa=C(),f(Q.$$.fragment),_a=C(),f(Qs.$$.fragment),wa=C(),f(X.$$.fragment),Ca=C(),f(Z.$$.fragment),va=C(),f(ss.$$.fragment),Ea=C(),f(as.$$.fragment),xa=C(),Xs=z("span"),Da=new T(!1),ba=C(),f(ns.$$.fragment),ka=C(),f(ts.$$.fragment),za=C(),Zs=z("span"),Aa=new T(!1),Ma=C(),f(es.$$.fragment),Ga=C(),f(ls.$$.fragment),Ta=C(),f(ps.$$.fragment),Sa=C(),f(os.$$.fragment),Wa=C(),f(is.$$.fragment),Ia=C(),sa=z("span"),La=new T(!1),Na=C(),f(rs.$$.fragment),Oa=C(),f(ms.$$.fragment),Pa=C(),f(cs.$$.fragment),qa=C(),f(fs.$$.fragment),ja=C(),f(hs.$$.fragment),Ba=C(),f($s.$$.fragment),Ra=C(),f(gs.$$.fragment),Ha=C(),f(ys.$$.fragment),Ua=C(),f(us.$$.fragment),Ja=C(),aa=z("span"),Va=new T(!1),Ya=C(),f(ds.$$.fragment),Ka=C(),na=z("span"),Qa=new T(!1),Xa=C(),f(Fs.$$.fragment),Za=C(),_s=z("div"),f(ws.$$.fragment),f(Cs.$$.fragment),sn=C(),f(vs.$$.fragment),an=C(),Es=z("div"),f(xs.$$.fragment),f(Ds.$$.fragment),nn=C(),f(bs.$$.fragment),tn=C(),f(ks.$$.fragment),en=C(),zs=z("div"),f(As.$$.fragment),f(Ms.$$.fragment),ln=C(),f(Gs.$$.fragment),pn=C(),f(ta.$$.fragment),on=C(),f(Ts.$$.fragment),rn=C(),f(Ss.$$.fragment),mn=C(),f(Ws.$$.fragment),cn=C(),f(ea.$$.fragment),fn=C(),f(Is.$$.fragment),hn=C(),f(Ls.$$.fragment),$n=C(),f(Ns.$$.fragment),gn=C(),f(la.$$.fragment),yn=C(),f(Os.$$.fragment),un=C(),f(Ps.$$.fragment),dn=C(),f(qs.$$.fragment),Fn=C(),f(js.$$.fragment),_n=C(),f(pa.$$.fragment),wn=C(),f(Bs.$$.fragment),Cn=C(),f(Rs.$$.fragment),vn=C(),f(Hs.$$.fragment),En=C(),f(oa.$$.fragment),xn=C(),f(Us.$$.fragment),Dn=C(),f(Js.$$.fragment),bn=C(),f(Vs.$$.fragment),this.h()},l(s){h(a.$$.fragment,s),n=v(s),h(t.$$.fragment,s),i=v(s),h(o.$$.fragment,s),m=v(s),h(w.$$.fragment,s),M=v(s),h(k.$$.fragment,s),D=v(s),h(E.$$.fragment,s),L=v(s),h(_.$$.fragment,s),c=v(s),h(x.$$.fragment,s),q=v(s),h(N.$$.fragment,s),B=v(s),h(j.$$.fragment,s),K=v(s),h(R.$$.fragment,s),G=v(s),h(P.$$.fragment,s),Ys=v(s),h(J.$$.fragment,s),Ks=v(s),h(Y.$$.fragment,s),Fa=v(s),h(Q.$$.fragment,s),_a=v(s),h(Qs.$$.fragment,s),wa=v(s),h(X.$$.fragment,s),Ca=v(s),h(Z.$$.fragment,s),va=v(s),h(ss.$$.fragment,s),Ea=v(s),h(as.$$.fragment,s),xa=v(s),Xs=A(s,"SPAN",{class:!0});var e=W(Xs);Da=S(e,!1),e.forEach(l),ba=v(s),h(ns.$$.fragment,s),ka=v(s),h(ts.$$.fragment,s),za=v(s),Zs=A(s,"SPAN",{class:!0});var ga=W(Zs);Aa=S(ga,!1),ga.forEach(l),Ma=v(s),h(es.$$.fragment,s),Ga=v(s),h(ls.$$.fragment,s),Ta=v(s),h(ps.$$.fragment,s),Sa=v(s),h(os.$$.fragment,s),Wa=v(s),h(is.$$.fragment,s),Ia=v(s),sa=A(s,"SPAN",{class:!0});var ya=W(sa);La=S(ya,!1),ya.forEach(l),Na=v(s),h(rs.$$.fragment,s),Oa=v(s),h(ms.$$.fragment,s),Pa=v(s),h(cs.$$.fragment,s),qa=v(s),h(fs.$$.fragment,s),ja=v(s),h(hs.$$.fragment,s),Ba=v(s),h($s.$$.fragment,s),Ra=v(s),h(gs.$$.fragment,s),Ha=v(s),h(ys.$$.fragment,s),Ua=v(s),h(us.$$.fragment,s),Ja=v(s),aa=A(s,"SPAN",{class:!0});var ua=W(aa);Va=S(ua,!1),ua.forEach(l),Ya=v(s),h(ds.$$.fragment,s),Ka=v(s),na=A(s,"SPAN",{class:!0});var da=W(na);Qa=S(da,!1),da.forEach(l),Xa=v(s),h(Fs.$$.fragment,s),Za=v(s),_s=A(s,"DIV",{"data-rehype-pretty-code-fragment":!0});var ma=W(_s);h(ws.$$.fragment,ma),h(Cs.$$.fragment,ma),ma.forEach(l),sn=v(s),h(vs.$$.fragment,s),an=v(s),Es=A(s,"DIV",{"data-rehype-pretty-code-fragment":!0});var ca=W(Es);h(xs.$$.fragment,ca),h(Ds.$$.fragment,ca),ca.forEach(l),nn=v(s),h(bs.$$.fragment,s),tn=v(s),h(ks.$$.fragment,s),en=v(s),zs=A(s,"DIV",{"data-rehype-pretty-code-fragment":!0});var fa=W(zs);h(As.$$.fragment,fa),h(Ms.$$.fragment,fa),fa.forEach(l),ln=v(s),h(Gs.$$.fragment,s),pn=v(s),h(ta.$$.fragment,s),on=v(s),h(Ts.$$.fragment,s),rn=v(s),h(Ss.$$.fragment,s),mn=v(s),h(Ws.$$.fragment,s),cn=v(s),h(ea.$$.fragment,s),fn=v(s),h(Is.$$.fragment,s),hn=v(s),h(Ls.$$.fragment,s),$n=v(s),h(Ns.$$.fragment,s),gn=v(s),h(la.$$.fragment,s),yn=v(s),h(Os.$$.fragment,s),un=v(s),h(Ps.$$.fragment,s),dn=v(s),h(qs.$$.fragment,s),Fn=v(s),h(js.$$.fragment,s),_n=v(s),h(pa.$$.fragment,s),wn=v(s),h(Bs.$$.fragment,s),Cn=v(s),h(Rs.$$.fragment,s),vn=v(s),h(Hs.$$.fragment,s),En=v(s),h(oa.$$.fragment,s),xn=v(s),h(Us.$$.fragment,s),Dn=v(s),h(Js.$$.fragment,s),bn=v(s),h(Vs.$$.fragment,s),this.h()},h(){Da.a=null,I(Xs,"class","text-sm md:text-lg"),Aa.a=null,I(Zs,"class","text-sm md:text-lg"),La.a=null,I(sa,"class","text-sm md:text-lg"),Va.a=null,I(aa,"class","text-sm md:text-lg"),Qa.a=null,I(na,"class","text-sm md:text-lg"),I(_s,"data-rehype-pretty-code-fragment",""),I(Es,"data-rehype-pretty-code-fragment",""),I(zs,"data-rehype-pretty-code-fragment","")},m(s,e){$(a,s,e),p(s,n,e),$(t,s,e),p(s,i,e),$(o,s,e),p(s,m,e),$(w,s,e),p(s,M,e),$(k,s,e),p(s,D,e),$(E,s,e),p(s,L,e),$(_,s,e),p(s,c,e),$(x,s,e),p(s,q,e),$(N,s,e),p(s,B,e),$(j,s,e),p(s,K,e),$(R,s,e),p(s,G,e),$(P,s,e),p(s,Ys,e),$(J,s,e),p(s,Ks,e),$(Y,s,e),p(s,Fa,e),$(Q,s,e),p(s,_a,e),$(Qs,s,e),p(s,wa,e),$(X,s,e),p(s,Ca,e),$(Z,s,e),p(s,va,e),$(ss,s,e),p(s,Ea,e),$(as,s,e),p(s,xa,e),p(s,Xs,e),Da.m(It,Xs),p(s,ba,e),$(ns,s,e),p(s,ka,e),$(ts,s,e),p(s,za,e),p(s,Zs,e),Aa.m(Lt,Zs),p(s,Ma,e),$(es,s,e),p(s,Ga,e),$(ls,s,e),p(s,Ta,e),$(ps,s,e),p(s,Sa,e),$(os,s,e),p(s,Wa,e),$(is,s,e),p(s,Ia,e),p(s,sa,e),La.m(Nt,sa),p(s,Na,e),$(rs,s,e),p(s,Oa,e),$(ms,s,e),p(s,Pa,e),$(cs,s,e),p(s,qa,e),$(fs,s,e),p(s,ja,e),$(hs,s,e),p(s,Ba,e),$($s,s,e),p(s,Ra,e),$(gs,s,e),p(s,Ha,e),$(ys,s,e),p(s,Ua,e),$(us,s,e),p(s,Ja,e),p(s,aa,e),Va.m(Ot,aa),p(s,Ya,e),$(ds,s,e),p(s,Ka,e),p(s,na,e),Qa.m(Pt,na),p(s,Xa,e),$(Fs,s,e),p(s,Za,e),p(s,_s,e),$(ws,_s,null),$(Cs,_s,null),p(s,sn,e),$(vs,s,e),p(s,an,e),p(s,Es,e),$(xs,Es,null),$(Ds,Es,null),p(s,nn,e),$(bs,s,e),p(s,tn,e),$(ks,s,e),p(s,en,e),p(s,zs,e),$(As,zs,null),$(Ms,zs,null),p(s,ln,e),$(Gs,s,e),p(s,pn,e),$(ta,s,e),p(s,on,e),$(Ts,s,e),p(s,rn,e),$(Ss,s,e),p(s,mn,e),$(Ws,s,e),p(s,cn,e),$(ea,s,e),p(s,fn,e),$(Is,s,e),p(s,hn,e),$(Ls,s,e),p(s,$n,e),$(Ns,s,e),p(s,gn,e),$(la,s,e),p(s,yn,e),$(Os,s,e),p(s,un,e),$(Ps,s,e),p(s,dn,e),$(qs,s,e),p(s,Fn,e),$(js,s,e),p(s,_n,e),$(pa,s,e),p(s,wn,e),$(Bs,s,e),p(s,Cn,e),$(Rs,s,e),p(s,vn,e),$(Hs,s,e),p(s,En,e),$(oa,s,e),p(s,xn,e),$(Us,s,e),p(s,Dn,e),$(Js,s,e),p(s,bn,e),$(Vs,s,e),kn=!0},p(s,e){const ga={};e&2&&(ga.$$scope={dirty:e,ctx:s}),a.$set(ga);const ya={};e&2&&(ya.$$scope={dirty:e,ctx:s}),t.$set(ya);const ua={};e&2&&(ua.$$scope={dirty:e,ctx:s}),o.$set(ua);const da={};e&2&&(da.$$scope={dirty:e,ctx:s}),w.$set(da);const ma={};e&2&&(ma.$$scope={dirty:e,ctx:s}),k.$set(ma);const ca={};e&2&&(ca.$$scope={dirty:e,ctx:s}),E.$set(ca);const fa={};e&2&&(fa.$$scope={dirty:e,ctx:s}),_.$set(fa);const Mn={};e&2&&(Mn.$$scope={dirty:e,ctx:s}),x.$set(Mn);const Gn={};e&2&&(Gn.$$scope={dirty:e,ctx:s}),N.$set(Gn);const Tn={};e&2&&(Tn.$$scope={dirty:e,ctx:s}),j.$set(Tn);const Sn={};e&2&&(Sn.$$scope={dirty:e,ctx:s}),R.$set(Sn);const Wn={};e&2&&(Wn.$$scope={dirty:e,ctx:s}),P.$set(Wn);const In={};e&2&&(In.$$scope={dirty:e,ctx:s}),J.$set(In);const Ln={};e&2&&(Ln.$$scope={dirty:e,ctx:s}),Q.$set(Ln);const Nn={};e&2&&(Nn.$$scope={dirty:e,ctx:s}),X.$set(Nn);const On={};e&2&&(On.$$scope={dirty:e,ctx:s}),Z.$set(On);const Pn={};e&2&&(Pn.$$scope={dirty:e,ctx:s}),ss.$set(Pn);const qn={};e&2&&(qn.$$scope={dirty:e,ctx:s}),as.$set(qn);const jn={};e&2&&(jn.$$scope={dirty:e,ctx:s}),ns.$set(jn);const Bn={};e&2&&(Bn.$$scope={dirty:e,ctx:s}),ts.$set(Bn);const Rn={};e&2&&(Rn.$$scope={dirty:e,ctx:s}),es.$set(Rn);const Hn={};e&2&&(Hn.$$scope={dirty:e,ctx:s}),ls.$set(Hn);const Un={};e&2&&(Un.$$scope={dirty:e,ctx:s}),ps.$set(Un);const Jn={};e&2&&(Jn.$$scope={dirty:e,ctx:s}),os.$set(Jn);const Vn={};e&2&&(Vn.$$scope={dirty:e,ctx:s}),is.$set(Vn);const Yn={};e&2&&(Yn.$$scope={dirty:e,ctx:s}),rs.$set(Yn);const Kn={};e&2&&(Kn.$$scope={dirty:e,ctx:s}),ms.$set(Kn);const Qn={};e&2&&(Qn.$$scope={dirty:e,ctx:s}),cs.$set(Qn);const Xn={};e&2&&(Xn.$$scope={dirty:e,ctx:s}),fs.$set(Xn);const Zn={};e&2&&(Zn.$$scope={dirty:e,ctx:s}),hs.$set(Zn);const st={};e&2&&(st.$$scope={dirty:e,ctx:s}),$s.$set(st);const at={};e&2&&(at.$$scope={dirty:e,ctx:s}),gs.$set(at);const nt={};e&2&&(nt.$$scope={dirty:e,ctx:s}),ys.$set(nt);const tt={};e&2&&(tt.$$scope={dirty:e,ctx:s}),us.$set(tt);const et={};e&2&&(et.$$scope={dirty:e,ctx:s}),ds.$set(et);const lt={};e&2&&(lt.$$scope={dirty:e,ctx:s}),Fs.$set(lt);const pt={};e&2&&(pt.$$scope={dirty:e,ctx:s}),ws.$set(pt);const ot={};e&2&&(ot.$$scope={dirty:e,ctx:s}),Cs.$set(ot);const it={};e&2&&(it.$$scope={dirty:e,ctx:s}),vs.$set(it);const rt={};e&2&&(rt.$$scope={dirty:e,ctx:s}),xs.$set(rt);const mt={};e&2&&(mt.$$scope={dirty:e,ctx:s}),Ds.$set(mt);const ct={};e&2&&(ct.$$scope={dirty:e,ctx:s}),bs.$set(ct);const ft={};e&2&&(ft.$$scope={dirty:e,ctx:s}),ks.$set(ft);const ht={};e&2&&(ht.$$scope={dirty:e,ctx:s}),As.$set(ht);const $t={};e&2&&($t.$$scope={dirty:e,ctx:s}),Ms.$set($t);const gt={};e&2&&(gt.$$scope={dirty:e,ctx:s}),Gs.$set(gt);const yt={};e&2&&(yt.$$scope={dirty:e,ctx:s}),Ts.$set(yt);const ut={};e&2&&(ut.$$scope={dirty:e,ctx:s}),Ss.$set(ut);const dt={};e&2&&(dt.$$scope={dirty:e,ctx:s}),Ws.$set(dt);const Ft={};e&2&&(Ft.$$scope={dirty:e,ctx:s}),Is.$set(Ft);const _t={};e&2&&(_t.$$scope={dirty:e,ctx:s}),Ls.$set(_t);const wt={};e&2&&(wt.$$scope={dirty:e,ctx:s}),Ns.$set(wt);const Ct={};e&2&&(Ct.$$scope={dirty:e,ctx:s}),Os.$set(Ct);const vt={};e&2&&(vt.$$scope={dirty:e,ctx:s}),Ps.$set(vt);const Et={};e&2&&(Et.$$scope={dirty:e,ctx:s}),qs.$set(Et);const xt={};e&2&&(xt.$$scope={dirty:e,ctx:s}),js.$set(xt);const Dt={};e&2&&(Dt.$$scope={dirty:e,ctx:s}),Bs.$set(Dt);const bt={};e&2&&(bt.$$scope={dirty:e,ctx:s}),Rs.$set(bt);const kt={};e&2&&(kt.$$scope={dirty:e,ctx:s}),Hs.$set(kt);const zt={};e&2&&(zt.$$scope={dirty:e,ctx:s}),Us.$set(zt);const At={};e&2&&(At.$$scope={dirty:e,ctx:s}),Js.$set(At);const Mt={};e&2&&(Mt.$$scope={dirty:e,ctx:s}),Vs.$set(Mt)},i(s){kn||(g(a.$$.fragment,s),g(t.$$.fragment,s),g(o.$$.fragment,s),g(w.$$.fragment,s),g(k.$$.fragment,s),g(E.$$.fragment,s),g(_.$$.fragment,s),g(x.$$.fragment,s),g(N.$$.fragment,s),g(j.$$.fragment,s),g(R.$$.fragment,s),g(P.$$.fragment,s),g(J.$$.fragment,s),g(Y.$$.fragment,s),g(Q.$$.fragment,s),g(Qs.$$.fragment,s),g(X.$$.fragment,s),g(Z.$$.fragment,s),g(ss.$$.fragment,s),g(as.$$.fragment,s),g(ns.$$.fragment,s),g(ts.$$.fragment,s),g(es.$$.fragment,s),g(ls.$$.fragment,s),g(ps.$$.fragment,s),g(os.$$.fragment,s),g(is.$$.fragment,s),g(rs.$$.fragment,s),g(ms.$$.fragment,s),g(cs.$$.fragment,s),g(fs.$$.fragment,s),g(hs.$$.fragment,s),g($s.$$.fragment,s),g(gs.$$.fragment,s),g(ys.$$.fragment,s),g(us.$$.fragment,s),g(ds.$$.fragment,s),g(Fs.$$.fragment,s),g(ws.$$.fragment,s),g(Cs.$$.fragment,s),g(vs.$$.fragment,s),g(xs.$$.fragment,s),g(Ds.$$.fragment,s),g(bs.$$.fragment,s),g(ks.$$.fragment,s),g(As.$$.fragment,s),g(Ms.$$.fragment,s),g(Gs.$$.fragment,s),g(ta.$$.fragment,s),g(Ts.$$.fragment,s),g(Ss.$$.fragment,s),g(Ws.$$.fragment,s),g(ea.$$.fragment,s),g(Is.$$.fragment,s),g(Ls.$$.fragment,s),g(Ns.$$.fragment,s),g(la.$$.fragment,s),g(Os.$$.fragment,s),g(Ps.$$.fragment,s),g(qs.$$.fragment,s),g(js.$$.fragment,s),g(pa.$$.fragment,s),g(Bs.$$.fragment,s),g(Rs.$$.fragment,s),g(Hs.$$.fragment,s),g(oa.$$.fragment,s),g(Us.$$.fragment,s),g(Js.$$.fragment,s),g(Vs.$$.fragment,s),kn=!0)},o(s){y(a.$$.fragment,s),y(t.$$.fragment,s),y(o.$$.fragment,s),y(w.$$.fragment,s),y(k.$$.fragment,s),y(E.$$.fragment,s),y(_.$$.fragment,s),y(x.$$.fragment,s),y(N.$$.fragment,s),y(j.$$.fragment,s),y(R.$$.fragment,s),y(P.$$.fragment,s),y(J.$$.fragment,s),y(Y.$$.fragment,s),y(Q.$$.fragment,s),y(Qs.$$.fragment,s),y(X.$$.fragment,s),y(Z.$$.fragment,s),y(ss.$$.fragment,s),y(as.$$.fragment,s),y(ns.$$.fragment,s),y(ts.$$.fragment,s),y(es.$$.fragment,s),y(ls.$$.fragment,s),y(ps.$$.fragment,s),y(os.$$.fragment,s),y(is.$$.fragment,s),y(rs.$$.fragment,s),y(ms.$$.fragment,s),y(cs.$$.fragment,s),y(fs.$$.fragment,s),y(hs.$$.fragment,s),y($s.$$.fragment,s),y(gs.$$.fragment,s),y(ys.$$.fragment,s),y(us.$$.fragment,s),y(ds.$$.fragment,s),y(Fs.$$.fragment,s),y(ws.$$.fragment,s),y(Cs.$$.fragment,s),y(vs.$$.fragment,s),y(xs.$$.fragment,s),y(Ds.$$.fragment,s),y(bs.$$.fragment,s),y(ks.$$.fragment,s),y(As.$$.fragment,s),y(Ms.$$.fragment,s),y(Gs.$$.fragment,s),y(ta.$$.fragment,s),y(Ts.$$.fragment,s),y(Ss.$$.fragment,s),y(Ws.$$.fragment,s),y(ea.$$.fragment,s),y(Is.$$.fragment,s),y(Ls.$$.fragment,s),y(Ns.$$.fragment,s),y(la.$$.fragment,s),y(Os.$$.fragment,s),y(Ps.$$.fragment,s),y(qs.$$.fragment,s),y(js.$$.fragment,s),y(pa.$$.fragment,s),y(Bs.$$.fragment,s),y(Rs.$$.fragment,s),y(Hs.$$.fragment,s),y(oa.$$.fragment,s),y(Us.$$.fragment,s),y(Js.$$.fragment,s),y(Vs.$$.fragment,s),kn=!1},d(s){s&&(l(n),l(i),l(m),l(M),l(D),l(L),l(c),l(q),l(B),l(K),l(G),l(Ys),l(Ks),l(Fa),l(_a),l(wa),l(Ca),l(va),l(Ea),l(xa),l(Xs),l(ba),l(ka),l(za),l(Zs),l(Ma),l(Ga),l(Ta),l(Sa),l(Wa),l(Ia),l(sa),l(Na),l(Oa),l(Pa),l(qa),l(ja),l(Ba),l(Ra),l(Ha),l(Ua),l(Ja),l(aa),l(Ya),l(Ka),l(na),l(Xa),l(Za),l(_s),l(sn),l(an),l(Es),l(nn),l(tn),l(en),l(zs),l(ln),l(pn),l(on),l(rn),l(mn),l(cn),l(fn),l(hn),l($n),l(gn),l(yn),l(un),l(dn),l(Fn),l(_n),l(wn),l(Cn),l(vn),l(En),l(xn),l(Dn),l(bn)),u(a,s),u(t,s),u(o,s),u(w,s),u(k,s),u(E,s),u(_,s),u(x,s),u(N,s),u(j,s),u(R,s),u(P,s),u(J,s),u(Y,s),u(Q,s),u(Qs,s),u(X,s),u(Z,s),u(ss,s),u(as,s),u(ns,s),u(ts,s),u(es,s),u(ls,s),u(ps,s),u(os,s),u(is,s),u(rs,s),u(ms,s),u(cs,s),u(fs,s),u(hs,s),u($s,s),u(gs,s),u(ys,s),u(us,s),u(ds,s),u(Fs,s),u(ws),u(Cs),u(vs,s),u(xs),u(Ds),u(bs,s),u(ks,s),u(As),u(Ms),u(Gs,s),u(ta,s),u(Ts,s),u(Ss,s),u(Ws,s),u(ea,s),u(Is,s),u(Ls,s),u(Ns,s),u(la,s),u(Os,s),u(Ps,s),u(qs,s),u(js,s),u(pa,s),u(Bs,s),u(Rs,s),u(Hs,s),u(oa,s),u(Us,s),u(Js,s),u(Vs,s)}}}function wl(r){let a,n;const t=[r[0],Wt];let i={$$slots:{default:[_l]},$$scope:{ctx:r}};for(let o=0;o<t.length;o+=1)i=An(i,t[o]);return a=new Ht({props:i}),{c(){f(a.$$.fragment)},l(o){h(a.$$.fragment,o)},m(o,m){$(a,o,m),n=!0},p(o,[m]){const w=m&1?Rt(t,[m&1&&Tt(o[0]),m&0&&Tt(Wt)]):{};m&2&&(w.$$scope={dirty:m,ctx:o}),a.$set(w)},i(o){n||(g(a.$$.fragment,o),n=!0)},o(o){y(a.$$.fragment,o),n=!1},d(o){u(a,o)}}}const Wt={title:"Gradient Descent: A Step-by-Step Guide to Optimization",description:"Explore the fundamental algorithm powering machine learning and deep learning",date:"2024-01-12",image:"/posts/gradient-descent/thumbnail.jpeg",tags:["Gradient Descent","Machine Learning"],draft:!1};function Cl(r,a,n){return r.$$set=t=>{n(0,a=An(An({},a),Gt(t)))},a=Gt(a),[a]}class Al extends jt{constructor(a){super(),Bt(this,a,Cl,wl,qt,{})}}export{Al as default,Wt as metadata};
