{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e5925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Norm Output:\n",
      " [[[ 1.70863676 -0.13629827 -1.72076935 ...  1.37047155  1.5369013\n",
      "   -1.06560742]\n",
      "  [-1.20663801 -0.84436428 -1.68322335 ... -0.54353955  1.09234572\n",
      "   -0.04310508]\n",
      "  [ 0.60521268 -1.09602991 -1.09374313 ... -0.48319579 -1.59319968\n",
      "    0.32805316]\n",
      "  ...\n",
      "  [-1.28043934 -0.86907098 -1.49960198 ...  0.41882009  0.14630969\n",
      "   -1.5746244 ]\n",
      "  [-0.15961256  0.21473206  1.06304736 ... -0.56396214  1.17502287\n",
      "    0.81103531]\n",
      "  [ 1.33351844 -1.26034282 -0.35312419 ...  0.54800968  0.62573213\n",
      "    0.07953197]]\n",
      "\n",
      " [[-0.83197789  1.36378319  0.53981356 ... -1.44848487  0.21912869\n",
      "   -0.90460137]\n",
      "  [-0.15420669 -0.40543469  0.55032146 ...  0.62326496  0.51842754\n",
      "   -1.60165968]\n",
      "  [-0.06761847  1.13465329  1.17519583 ...  1.72640612  0.08282305\n",
      "    0.22611451]\n",
      "  ...\n",
      "  [-0.4092746   1.51054338  0.14379908 ...  1.34138976  0.9147942\n",
      "   -0.12218639]\n",
      "  [ 1.19074324 -1.68765569  0.52295837 ... -1.35556804  0.22664898\n",
      "   -1.70986371]\n",
      "  [-0.61642744  1.23352504  1.22393031 ...  0.44433029  1.30317029\n",
      "   -1.34724392]]\n",
      "\n",
      " [[-0.48348703 -1.44082612  0.43214677 ...  0.13943287 -1.03296469\n",
      "    1.2145056 ]\n",
      "  [ 1.57310666 -0.45711804  0.89964077 ... -1.32688023 -1.59299984\n",
      "    0.62215945]\n",
      "  [ 1.05116127  0.84972652 -0.88306582 ... -0.54028812  1.15150061\n",
      "   -1.63478679]\n",
      "  ...\n",
      "  [ 1.46347198  0.29451747  1.3148402  ... -1.36780101 -1.66605057\n",
      "    1.03008595]\n",
      "  [-1.52179265  0.83749278  0.02487788 ...  0.98575125 -1.59121547\n",
      "    0.36418255]\n",
      "  [-1.24865597 -0.65347739 -1.43492383 ...  0.73058245 -0.80658499\n",
      "   -0.1952903 ]]\n",
      "\n",
      " [[-0.39317183  0.21334119  0.74880902 ... -0.06141955 -0.7230653\n",
      "    0.75570319]\n",
      "  [-0.21226197  1.70691702  0.23326112 ...  1.24715481 -0.01777342\n",
      "    1.02260531]\n",
      "  [-1.58875548 -0.8883499   0.80161312 ... -0.70292221  0.35887602\n",
      "    1.08061912]\n",
      "  ...\n",
      "  [ 0.22624196 -0.93598987  0.0409627  ... -0.39240884  0.60494668\n",
      "    0.66672484]\n",
      "  [ 0.49066197  0.63543086 -1.61088361 ...  0.93377893  0.18954361\n",
      "    0.53464585]\n",
      "  [ 0.53156497  0.68029516  0.56411771 ... -1.72292242 -1.12231743\n",
      "    1.46300225]]]\n",
      "Layer Norm Output:\n",
      " [[[ 1.93964683 -0.37326147 -1.40231806 ...  0.60207373  0.27432321\n",
      "   -1.09463778]\n",
      "  [-0.75589749 -1.17879203 -0.45052884 ... -1.22288288  0.80311931\n",
      "    0.44554443]\n",
      "  [ 0.8532708  -0.22191758  1.39734796 ... -0.66936677 -0.61528262\n",
      "    0.59827864]\n",
      "  ...\n",
      "  [-1.21602703  0.17374652 -0.81463482 ... -0.96874168 -0.78633557\n",
      "   -1.59270073]\n",
      "  [-0.55418792  0.22708542  0.67357482 ...  1.84410751  1.74547047\n",
      "    1.22648014]\n",
      "  [ 0.64523556 -1.49355208  0.3083411  ...  0.85045079  0.30360395\n",
      "    0.89493264]]\n",
      "\n",
      " [[-0.62374435  1.22733833 -0.76966827 ... -0.90340203 -1.10966482\n",
      "   -1.10676544]\n",
      "  [-0.81081564 -0.45683348 -0.28338275 ... -0.11850234  0.3029731\n",
      "   -1.90266882]\n",
      "  [ 1.23993558  1.04688639  1.1524993  ...  2.29594622  0.52208354\n",
      "    0.96460445]\n",
      "  ...\n",
      "  [-0.6626427   0.98859144  0.20456878 ... -0.51239788 -0.30417829\n",
      "    0.33262734]\n",
      "  [ 1.1865663  -0.22802913 -0.9572781  ...  0.61660821  1.27230702\n",
      "   -0.18316124]\n",
      "  [-1.56510619  0.25992025  0.56302976 ...  0.11634103  1.50231166\n",
      "    0.14351487]]\n",
      "\n",
      " [[ 0.1224635  -1.7924809  -0.49011817 ...  0.17968343 -0.55703482\n",
      "   -0.78257426]\n",
      "  [ 0.09097464 -0.71496974  0.18671051 ... -0.80771155 -0.61492156\n",
      "    0.60210965]\n",
      "  [ 1.46563359  0.87951934  0.23437165 ... -0.14166169  2.1182756\n",
      "   -1.86331162]\n",
      "  ...\n",
      "  [ 1.50735592  0.46590286  1.7959461  ... -0.75333731 -1.23445027\n",
      "    0.93873116]\n",
      "  [-1.37631155  0.14832505 -0.6785535  ...  1.43118699  0.44115761\n",
      "   -0.16712968]\n",
      "  [-1.21559768 -0.78562449 -1.67808099 ...  0.79146232 -0.31344017\n",
      "   -0.7132417 ]]\n",
      "\n",
      " [[ 0.11233743 -0.49244254 -0.66542903 ...  0.22318624 -0.83856244\n",
      "   -0.71862938]\n",
      "  [-1.39768888  0.01960056 -0.59147949 ...  0.85449852  0.41664061\n",
      "    1.31894431]\n",
      "  [-1.49352431 -0.86835323  1.12673302 ... -0.23516481  1.2942623\n",
      "   -0.14058184]\n",
      "  ...\n",
      "  [ 0.48857457 -0.63839938  0.07090876 ... -0.39645885  0.22246047\n",
      "    0.23932686]\n",
      "  [-0.09967637 -0.26931677 -1.84274154 ...  1.58470118  1.6296395\n",
      "    0.28438442]\n",
      "  [ 0.25825417 -0.81880287 -0.17312657 ... -1.39608343 -1.21615987\n",
      "    1.28874193]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BatchNormLayer:\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.running_mean = np.zeros(num_features)\n",
    "        self.running_var = np.ones(num_features)\n",
    "        self.gamma = np.ones(num_features)\n",
    "        self.beta = np.zeros(num_features)\n",
    "\n",
    "    def forward(self, x, training=True):\n",
    "        # 修正：BatchNorm应该在batch和spatial维度上计算统计量\n",
    "        # 对于3D输入 (batch_size, seq_len, features)，在axis=(0,1)上计算\n",
    "        if training:\n",
    "            batch_mean = np.mean(x, axis=(0, 1))  # 修正：在batch和sequence维度上求均值\n",
    "            batch_var = np.var(x, axis=(0, 1))   # 修正：在batch和sequence维度上求方差\n",
    "            x_normalized = (x - batch_mean) / np.sqrt(batch_var + self.eps)\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * batch_mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * batch_var\n",
    "        else:\n",
    "            x_normalized = (x - self.running_mean) / np.sqrt(self.running_var + self.eps)\n",
    "        \n",
    "        out = self.gamma * x_normalized + self.beta\n",
    "        return out\n",
    "\n",
    "class LayerNormLayer:\n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.gamma = np.ones(num_features)\n",
    "        self.beta = np.zeros(num_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LayerNorm在最后一个维度(特征维度)上计算统计量\n",
    "        mean = np.mean(x, axis=-1, keepdims=True)  # 修正：在特征维度上求均值\n",
    "        var = np.var(x, axis=-1, keepdims=True)    # 修正：在特征维度上求方差\n",
    "        x_normalized = (x - mean) / np.sqrt(var + self.eps)\n",
    "        out = self.gamma * x_normalized + self.beta\n",
    "        return out\n",
    "\n",
    "class GroupNormLayer:\n",
    "    def __init__(self, num_features, num_groups=32, eps=1e-5):\n",
    "        assert num_features % num_groups == 0, \"num_features must be divisible by num_groups\"\n",
    "        self.num_features = num_features\n",
    "        self.num_groups = num_groups\n",
    "        self.eps = eps\n",
    "        self.gamma = np.ones(num_features)\n",
    "        self.beta = np.zeros(num_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C = x.shape[0], x.shape[-1]\n",
    "        G = self.num_groups\n",
    "        x = x.reshape(N, -1, G, C // G)  # Reshape to (N, *, G, C//G)\n",
    "        \n",
    "        mean = np.mean(x, axis=(1, 3), keepdims=True)  # Mean over (spatial and feature) dimensions\n",
    "        var = np.var(x, axis=(1, 3), keepdims=True)    # Variance over (spatial and feature) dimensions\n",
    "        \n",
    "        x_normalized = (x - mean) / np.sqrt(var + self.eps)\n",
    "        x_normalized = x_normalized.reshape(N, -1, C)  # Reshape back to original shape\n",
    "        \n",
    "        out = self.gamma * x_normalized + self.beta\n",
    "        return out\n",
    "    \n",
    "\n",
    "# 测试代码\n",
    "batch_data = np.random.randn(4, 8, 64)\n",
    "print(\"输入数据形状:\", batch_data.shape)\n",
    "\n",
    "# BatchNorm: 在批次和序列维度上标准化\n",
    "batch_norm = BatchNormLayer(num_features=64)\n",
    "batch_norm_output = batch_norm.forward(batch_data)\n",
    "\n",
    "# LayerNorm: 在特征维度上标准化  \n",
    "layer_norm = LayerNormLayer(num_features=64)\n",
    "layer_norm_output = layer_norm.forward(batch_data)\n",
    "\n",
    "print(f\"BatchNorm输出形状: {batch_norm_output.shape}\")\n",
    "print(f\"LayerNorm输出形状: {layer_norm_output.shape}\")\n",
    "\n",
    "# 验证标准化效果\n",
    "print(f\"\\nBatchNorm后每个特征的均值(应该接近0): {np.mean(batch_norm_output, axis=(0,1))[:5]}\")\n",
    "print(f\"LayerNorm后每个样本的均值(应该接近0): {np.mean(layer_norm_output, axis=-1)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db42be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "简单数据:\n",
      " [[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "BatchNorm均值:\n",
      " [4. 5.]\n",
      "BatchNorm方差:\n",
      " [5. 5.]\n",
      "LayerNorm均值:\n",
      " [[[1.5]\n",
      "  [3.5]]\n",
      "\n",
      " [[5.5]\n",
      "  [7.5]]]\n",
      "LayerNorm方差:\n",
      " [[[0.25]\n",
      "  [0.25]]\n",
      "\n",
      " [[0.25]\n",
      "  [0.25]]]\n"
     ]
    }
   ],
   "source": [
    "# 举例讲解batch_mean = np.mean(x, axis=(0, 1))  # 修正：在batch和sequence维度上求均值\n",
    "simple_data = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # shape (2, 2, 2)\n",
    "print(\"\\n简单数据:\\n\", simple_data)\n",
    "# sim batchnorm\n",
    "batch_mean = np.mean(simple_data, axis=(0, 1))  # 在batch和sequence维度上求均值\n",
    "batch_var = np.var(simple_data, axis=(0, 1))    # 在batch和sequence维度上求方差\n",
    "print(\"BatchNorm均值:\\n\", batch_mean)\n",
    "print(\"BatchNorm方差:\\n\", batch_var)\n",
    "\n",
    "# sim layernorm\n",
    "layer_mean = np.mean(simple_data, axis=-1, keepdims=True)  # 在特征维度上求均值\n",
    "layer_var = np.var(simple_data, axis=-1, keepdims=True)    # 在特征维度上求方差\n",
    "print(\"LayerNorm均值:\\n\", layer_mean)\n",
    "print(\"LayerNorm方差:\\n\", layer_var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
